{"paragraphs":[{"text":"%md\n# IberIA - Construcción del conjunto de datos final","user":"jmarti32","dateUpdated":"2025-04-15T00:12:52+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>IberIA - Construcción del conjunto de datos final</h1>\n\n</div>"}]},"apps":[],"jobName":"paragraph_1744633253406_-437063706","id":"20250414-122053_1259002683","dateCreated":"2025-04-14T12:20:53+0000","dateStarted":"2025-04-15T00:12:52+0000","dateFinished":"2025-04-15T00:12:52+0000","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:4113"},{"text":"%md\n## Pipeline\n\n#### 1. Decodificamos mensajes y convertimos en dataframe","user":"jmarti32","dateUpdated":"2025-04-15T00:12:52+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h2>Pipeline</h2>\n<h4>1. Decodificamos mensajes y convertimos en dataframe</h4>\n\n</div>"}]},"apps":[],"jobName":"paragraph_1744633338526_827613790","id":"20250414-122218_1904992776","dateCreated":"2025-04-14T12:22:18+0000","dateStarted":"2025-04-15T00:12:52+0000","dateFinished":"2025-04-15T00:12:52+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4114"},{"text":"%livy3.pyspark\nspark.conf.set(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")","user":"jmarti32","dateUpdated":"2025-04-15T00:12:52+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1744647600950_-272820716","id":"20250414-162000_1388059275","dateCreated":"2025-04-14T16:20:00+0000","dateStarted":"2025-04-15T00:12:52+0000","dateFinished":"2025-04-15T00:13:18+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4115"},{"text":"%livy3.pyspark\ndf_raw = spark.read.parquet(\"/data/proyecto2/outputs/iberIA/dia11Completo.parquet\")","user":"jmarti32","dateUpdated":"2025-04-15T00:13:18+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python","editorHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1744629870211_-254567347","id":"20250414-112430_1972390716","dateCreated":"2025-04-14T11:24:30+0000","dateStarted":"2025-04-15T00:13:18+0000","dateFinished":"2025-04-15T00:13:21+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4116"},{"text":"%livy3.pyspark\ndf_raw.printSchema()","user":"jmarti32","dateUpdated":"2025-04-15T00:13:21+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python","editorHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"root\n |-- Timestamp (date): timestamp (nullable = true)\n |-- Timestamp (kafka): integer (nullable = true)\n |-- Typecode: integer (nullable = true)\n |-- TurbulenceCategory: string (nullable = true)\n |-- Downlink Format: integer (nullable = true)\n |-- Flight status: string (nullable = true)\n |-- Message (hex): string (nullable = true)\n |-- ICAO: string (nullable = true)\n |-- Message (base64): string (nullable = true)\n |-- Position with ref (RADAR): string (nullable = true)\n |-- lon: float (nullable = true)\n |-- Altitude (ft): float (nullable = true)\n |-- lat: float (nullable = true)\n |-- Static air temperature (C): float (nullable = true)\n |-- Average static pressure (hPa): float (nullable = true)\n |-- MCP/FCU selected altitude (ft): float (nullable = true)\n |-- Icing level (0-3): integer (nullable = true)\n |-- Barometric pressure (mb): float (nullable = true)\n |-- BDS: string (nullable = true)\n |-- Wind shear level (0-3): integer (nullable = true)\n |-- Turbulence level (0-3): integer (nullable = true)\n |-- FMS selected altitude (ft): float (nullable = true)\n |-- Wake vortex level (0-3): integer (nullable = true)\n |-- Radio height (ft): float (nullable = true)\n |-- Microburst level (0-3): integer (nullable = true)\n |-- Speed: float (nullable = true)\n |-- Angle: float (nullable = true)\n |-- Vertical rate: float (nullable = true)\n |-- Speed type: float (nullable = true)\n |-- Mach number (-): float (nullable = true)\n |-- Barometric altitude rate (ft/min): float (nullable = true)\n |-- Indicated airspeed (kt): float (nullable = true)\n |-- Squawk code: string (nullable = true)\n |-- Magnetic heading (deg): float (nullable = true)\n |-- Inertial vertical speed (ft/min): float (nullable = true)\n |-- Speed heading: string (nullable = true)\n |-- Roll angle (deg): float (nullable = true)\n |-- Ground speed (kt): float (nullable = true)\n |-- True airspeed (kt): float (nullable = true)\n |-- True track angle (deg): float (nullable = true)\n |-- Track angle rate (deg/sec): float (nullable = true)\n |-- Callsign: string (nullable = true)\n |-- Overlay capability: string (nullable = true)\n |-- Wind speed (kt) and direction (true) (deg): string (nullable = true)\n |-- Humidity (%): float (nullable = true)\n |-- GICB capability: string (nullable = true)"}]},"apps":[],"jobName":"paragraph_1744634624983_-870628065","id":"20250414-124344_1109469071","dateCreated":"2025-04-14T12:43:44+0000","dateStarted":"2025-04-15T00:13:21+0000","dateFinished":"2025-04-15T00:13:22+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4117"},{"text":"%md\n#### 2. Separamos dataframes de posiciones, callsigns, velocidades y categorías de turbulencia. Decodificamos mensajes y convertimos en dataframe","user":"jmarti32","dateUpdated":"2025-04-15T00:13:22+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h4>2. Separamos dataframes de posiciones, callsigns, velocidades y categorías de turbulencia. Decodificamos mensajes y convertimos en dataframe</h4>\n\n</div>"}]},"apps":[],"jobName":"paragraph_1744633425603_1174525763","id":"20250414-122345_1064689098","dateCreated":"2025-04-14T12:23:45+0000","dateStarted":"2025-04-15T00:13:22+0000","dateFinished":"2025-04-15T00:13:22+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4118"},{"text":"%livy3.pyspark\nfrom pyspark.sql import functions as F\ndef getPositions(df):\n        \"\"\"\n        Genera un DataFrame con los datos necesarios para visualizar las posiciones.\n        \n        Parámetros:\n            df: DataFrame de datos\n\n        Devuelve:\n            DataFrame con las siguientes columnas: \"Timestamp (date)\", \"ICAO\", \"Flight status\", \"lat\", \"lon\".\n        \"\"\"\n        df_pos = df.filter((F.col(\"Typecode\") >= 5) & (F.col(\"Typecode\") <= 22) & (F.col(\"Typecode\") != 19))\\\n               .select(\"Timestamp (date)\", \"ICAO\", \"Flight status\", \"lat\", \"lon\")\\\n               .distinct()\n        \n        return df_pos\n    \n\ndef getAirplaneCategories(df):\n    \"\"\"\n    Genera un DataFrame con la categoría de cada aeronave.\n    \n    Parámetros:\n        df: DataFrame de datos.\n\n    Devuelve:\n        DataFrame con las siguientes columnas: \"ICAO\", \"TurbulenceCategory\".\n    \"\"\"\n    # Seleccionamos mensajes ADS-B\n    df_filtered = df.filter(F.col(\"Downlink Format\").isin([17, 18]))\n\n    # Nos quedamos con los ICAOs y su tipo de avión\n    df_filtered = df_filtered.filter(F.col(\"TurbulenceCategory\").isNotNull() & (F.col(\"TurbulenceCategory\") != \"None\") & (~F.isnan(F.col(\"TurbulenceCategory\"))))\n\n    df_result = df_filtered.select(\"ICAO\", \"TurbulenceCategory\").dropDuplicates()\n\n    return df_result\n\n\ndef getFlights(df):\n    \"\"\"\n    Genera un DataFrame con los datos de vuelo.\n    \n    Parámetros:\n        df: DataFrame de datos.\n\n    Devuelve:\n        DataFrame con las siguientes columnas: \"Timestamp (date)\", \"ICAO\", \"Callsign\".\n    \"\"\"\n    NULL_CALLSIGN = \"########\"  # valor de nulo de la columna\n\n    # Seleccionamos las filas que contengan información relativa al identificador de vuelo\n    df_flights = df.filter((F.col(\"Callsign\").isNotNull()) & \n                           (F.col(\"Callsign\") != NULL_CALLSIGN) & \n                           (~F.isnan(F.col(\"Callsign\"))))\\\n               .select(\"Timestamp (date)\", \"ICAO\", \"Callsign\")\\\n               .distinct()  # Para evitar duplicados si es necesario\n\n\n    return df_flights\n    \ndef getAltitudes(df):\n        \"\"\"\n        Genera un Dataframe con los datos necesarios para visualizar las altitudes.\n        \n        Parámetros:\n            df: DataFrame de datos.\n\n        Devuelve:\n            DataFrame con las siguientes columnas: \"Timestamp (date)\", \"ICAO\", \"Callsign\", \"Flight status\", \"Altitude (ft)\", \"lat\", \"lon\".\n        \"\"\"\n        # DataFrame filtrando las filas que contienen una altitud no nula\n        df_alt = df.filter(F.col(\"Altitude (ft)\").isNotNull()  & (~F.isnan(F.col(\"Speed\"))))\\\n               .select(\"Timestamp (date)\", \"ICAO\", \"Callsign\", \"Flight status\", \"Altitude (ft)\", \"lat\", \"lon\")\n\n        return df_alt\n        \ndef getVelocities(df):\n    \"\"\"\n    Genera un dataframe con los mensajes relativos a la velocidad.\n\n    Parámetros:\n        df: DataFrame de datos.\n\n    Devuelve:\n        DataFrame con las siguientes columnas: \"Timestamp (date)\", \"ICAO\", \"Flight status\", \"Speed\", \"lat\", \"lon\".\n    \"\"\"\n    # Filtramos las filas donde la velocidad no es nula\n    df_vel = df.filter(F.col(\"Speed\").isNotNull() & (~F.isnan(F.col(\"Speed\"))))\\\n           .select(\"Timestamp (date)\", \"ICAO\", \"Flight status\", \"Speed\")\n    \n    return df_vel","user":"jmarti32","dateUpdated":"2025-04-15T00:13:22+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python","editorHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1744633529960_1449717349","id":"20250414-122529_959130399","dateCreated":"2025-04-14T12:25:29+0000","dateStarted":"2025-04-15T00:13:22+0000","dateFinished":"2025-04-15T00:13:23+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4119"},{"text":"%livy3.pyspark\n\n# posiciones\ndf_pos = getPositions(df_raw)\n\n# vuelos\ndf_flights = getFlights(df_raw)\n\n# categorías de turbulencia\ndf_types = getAirplaneCategories(df_raw)\n\n# velocidades\ndf_speed = getVelocities(df_raw)\n\n# altitudes\ndf_alt = getAltitudes(df_raw)","user":"jmarti32","dateUpdated":"2025-04-15T00:13:23+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python","editorHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1744633497843_970597368","id":"20250414-122457_1935557569","dateCreated":"2025-04-14T12:24:57+0000","dateStarted":"2025-04-15T00:13:23+0000","dateFinished":"2025-04-15T00:13:24+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4120"},{"text":"%livy3.pyspark","user":"jmarti32","dateUpdated":"2025-04-15T00:08:51+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1744653030709_-745610769","id":"20250414-175030_1839296427","dateCreated":"2025-04-14T17:50:30+0000","dateStarted":"2025-04-14T20:53:00+0000","dateFinished":"2025-04-14T20:53:01+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4121"},{"text":"%md\n#### 3. Filtramos para posiciones cercanas al aeropuerto (radio de 5km)","user":"jmarti32","dateUpdated":"2025-04-15T00:13:24+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h4>3. Filtramos para posiciones cercanas al aeropuerto (radio de 5km)</h4>\n\n</div>"}]},"apps":[],"jobName":"paragraph_1744634126055_1586607660","id":"20250414-123526_1879407803","dateCreated":"2025-04-14T12:35:26+0000","dateStarted":"2025-04-15T00:13:24+0000","dateFinished":"2025-04-15T00:13:24+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4122"},{"text":"%livy3.pyspark\n\nfrom pyspark.sql.functions import lit, radians, sin, cos, acos, col\n\nAIRPORT_CENTER_LAT = 40.49291\nAIRPORT_CENTER_LON = -3.56974 \nRADIUS_AIRPORT = 5000\n\ndef filter_positions_within_radius(df, lat_col=\"lat\", lon_col=\"lon\", lat_ref= AIRPORT_CENTER_LAT, lon_ref=AIRPORT_CENTER_LON, radius_m=RADIUS_AIRPORT):\n    \"\"\"\n    Filtra un DataFrame de PySpark para conservar solo los registros que están dentro de un radio específico\n    desde un punto de referencia, usando la fórmula de Haversine.\n\n    :param df: DataFrame de entrada con columnas de latitud y longitud\n    :param lat_col: Nombre de la columna de latitud en el DataFrame\n    :param lon_col: Nombre de la columna de longitud en el DataFrame\n    :param lat_ref: Latitud del punto de referencia\n    :param lon_ref: Longitud del punto de referencia\n    :param radius_m: Radio en metros para el filtrado (por defecto 5000 m)\n    :return: DataFrame filtrado con una columna adicional 'distance_ref'\n    \"\"\"\n    R = 6371000  # Radio de la Tierra en metros\n\n    # Calcular distancia\n    distance_expr = R * acos(\n        sin(radians(lit(lat_ref))) * sin(radians(col(lat_col))) +\n        cos(radians(lit(lat_ref))) * cos(radians(col(lat_col))) *\n        cos(radians(lit(lon_ref)) - radians(col(lon_col)))\n    )\n\n    # Calculamos la distancia con respecto al punto de referencia\n    df_with_dist = df.withColumn(\"distance_ref\", distance_expr)\n\n    # Nos quedamos solo con las posiciones que no superan la distancia radius_m\n    filtered_df = df_with_dist.filter(col(\"distance_ref\") <= radius_m)\n\n    # Eliminamos la columna 'distance_ref'\n    return filtered_df.drop(\"distance_ref\")","user":"jmarti32","dateUpdated":"2025-04-15T00:13:25+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python","editorHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1744634232098_516675514","id":"20250414-123712_842877239","dateCreated":"2025-04-14T12:37:12+0000","dateStarted":"2025-04-15T00:13:25+0000","dateFinished":"2025-04-15T00:13:26+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4123"},{"text":"%livy3.pyspark\ndf_pos_airport = filter_positions_within_radius(df_pos)","user":"jmarti32","dateUpdated":"2025-04-15T00:13:26+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python","editorHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1744634350388_794877855","id":"20250414-123910_1406723947","dateCreated":"2025-04-14T12:39:10+0000","dateStarted":"2025-04-15T00:13:26+0000","dateFinished":"2025-04-15T00:13:27+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4124"},{"text":"%md\n#### 4. Combinar posiciones con callsigns","user":"jmarti32","dateUpdated":"2025-04-15T00:13:27+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h4>4. Combinar posiciones con callsigns</h4>\n\n</div>"}]},"apps":[],"jobName":"paragraph_1744634538296_1752352591","id":"20250414-124218_1688459150","dateCreated":"2025-04-14T12:42:18+0000","dateStarted":"2025-04-15T00:13:27+0000","dateFinished":"2025-04-15T00:13:27+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4125"},{"text":"%livy3.pyspark\n\n# Merge de posiciones y estado de vuelo\nTOLERANCE_CALLSIGN_ASSIGNMENT = 600  # 10 minutos en segundos\ndf_pos_airport = df_pos_airport.withColumn(\"Timestamp_sec\", F.unix_timestamp(\"Timestamp (date)\"))\ndf_flights = df_flights.withColumn(\"Timestamp_sec\", F.unix_timestamp(\"Timestamp (date)\"))\n\ndf_pos_airport = df_pos_airport.withColumnRenamed(\"Timestamp_sec\", \"Timestamp_sec_pos\") \\\n                               .withColumnRenamed(\"Timestamp (date)\", \"Timestamp\")\n\ndf_flights = df_flights.withColumnRenamed(\"Timestamp_sec\", \"Timestamp_sec_flight\") \\\n                       .withColumnRenamed(\"Timestamp (date)\", \"Timestamp_flight\")\n\ndf_pos_callsign = df_pos_airport.join(df_flights, on=\"ICAO\", how=\"inner\").filter(\n    F.abs(df_pos_airport[\"Timestamp_sec_pos\"] - df_flights[\"Timestamp_sec_flight\"]) <= TOLERANCE_CALLSIGN_ASSIGNMENT\n)\n\ndf_pos_callsign = df_pos_callsign.drop(\"Timestamp_sec_flight\", \"Timestamp_sec_pos\", \"Timestamp_flight\")\ndf_pos_callsign = df_pos_callsign.dropDuplicates([\"ICAO\", \"Timestamp\"])\n","user":"jmarti32","dateUpdated":"2025-04-15T00:13:27+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python","editorHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1744634036405_1284624036","id":"20250414-123356_1453165726","dateCreated":"2025-04-14T12:33:56+0000","dateStarted":"2025-04-15T00:13:27+0000","dateFinished":"2025-04-15T00:13:28+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4126"},{"text":"%md\n#### 6. Detección de aeronaves situados en puntos de espera","user":"jmarti32","dateUpdated":"2025-04-15T00:13:28+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h4>6. Detección de aeronaves situados en puntos de espera</h4>\n\n</div>"}]},"apps":[],"jobName":"paragraph_1744635433034_-1501749587","id":"20250414-125713_2127398844","dateCreated":"2025-04-14T12:57:13+0000","dateStarted":"2025-04-15T00:13:28+0000","dateFinished":"2025-04-15T00:13:28+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4127"},{"text":"%livy3.pyspark\nfrom pyspark.sql.functions import udf\nfrom pyspark.sql.types import StringType, StructType, StructField\nimport math\n\n# Función para calcular la distancia de Haversine\ndef haversine_distance(lat1, lon1, lat2, lon2):\n    R = 6371000  # Radio de la Tierra en metros\n    lat1_rad = math.radians(float(lat1))\n    lon1_rad = math.radians(float(lon1))\n    lat2_rad = math.radians(float(lat2))\n    lon2_rad = math.radians(float(lon2))\n    \n    return R * math.acos(\n        math.sin(lat1_rad) * math.sin(lat2_rad) +\n        math.cos(lat1_rad) * math.cos(lat2_rad) * math.cos(lon1_rad - lon2_rad)\n    )\n\n# UDF para asignar Designator y Runway basado en la distancia\ndef assign_designator_runway(lat, lon, holding_points):\n    # Inicializamos el valor de retorno como None\n    \n    DIST_THRESHOLD = 20\n    \n    closest_designator = None\n    closest_runway = None\n    min_distance = float(\"inf\")  # Inicializamos con un valor grande\n    \n    # Iteramos sobre los puntos de espera para encontrar el más cercano\n    for hold in holding_points:\n        designator, runway, lon_p, lat_p = hold\n        dist = haversine_distance(lat, lon, lat_p, lon_p)\n        \n        # Si la distancia es menor a 20 metros, devolvemos el primer punto\n        if dist < DIST_THRESHOLD:\n            closest_designator = designator\n            closest_runway = runway\n            break  # Detenemos la búsqueda una vez encontramos el primer punto cercano\n    \n    return (closest_designator, closest_runway)\n\n# Diccionario de puntos de espera\nholding_points = [\n    (\"Z1\", \"36L/18R\", -3.573093114831562, 40.490653160130186),\n    (\"KA6\", \"32R/14L\", -3.537524367869231, 40.472076292010001),\n    (\"KA8\", \"32R/14L\", -3.536653485337274, 40.466622566754253),\n    (\"K3\", \"32R/14L\", -3.558959606954449, 40.494122669084419),\n    (\"K2\", \"32R/14L\", -3.559326044131887, 40.4945961819448),\n    (\"K1\", \"32R/14L\", -3.560411408421098, 40.495554592925956),\n    (\"Y1\", \"36R/18L\", -3.560656492186808, 40.499431092287409),\n    (\"Y2\", \"36R/18L\", -3.560645785166937, 40.500298406173002),\n    (\"Y3\", \"36R/18L\", -3.560660061193443, 40.501183565039504),\n    (\"Y7\", \"36R/18L\", -3.560800449906033, 40.533391949745102),\n    (\"Z6\", \"36L/18R\", -3.576129307304151, 40.495184843931881),\n    (\"Z4\", \"36L/18R\", -3.576034129003182, 40.492555539298088),\n    (\"Z2\", \"36L/18R\", -3.575903257941006, 40.491865496230126),\n    (\"Z3\", \"36L/18R\", -3.57319305240692, 40.491819096186241),\n    (\"LF\", \"32L/14R\", -3.572566658955927, 40.479721203031424),\n    (\"L1\", \"32L/14R\", -3.57652786733783, 40.483565816902733),\n    (\"LA\", \"32L/14R\", -3.577181028787666, 40.484251101106899),\n    (\"LB\", \"32L/14R\", -3.577553413710587, 40.484873329796898),\n    (\"LC\", \"32L/14R\", -3.575750378154376, 40.486690643924192),\n    (\"LD\", \"32L/14R\", -3.575150753600524, 40.486522892072891),\n    (\"LE\", \"32L/14R\", -3.574915186586964, 40.485580625293494)\n]\n\n# Esquema para la UDF (dos campos de tipo String: Designator y Runway)\nschema = StructType([\n    StructField(\"Designator\", StringType(), True),\n    StructField(\"Runway\", StringType(), True)\n])\n\n# Registrar la UDF con el tipo de retorno correcto (STRUCT)\nassign_udf = udf(lambda lat, lon: assign_designator_runway(lat, lon, holding_points), schema)","user":"jmarti32","dateUpdated":"2025-04-15T00:13:28+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python","editorHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1744635220176_2004385150","id":"20250414-125340_714598933","dateCreated":"2025-04-14T12:53:40+0000","dateStarted":"2025-04-15T00:13:28+0000","dateFinished":"2025-04-15T00:13:29+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4128"},{"text":"%livy3.pyspark\n\n# Asignamos puntos de espera\ndf_with_hp = df_pos_callsign.withColumn(\n    \"Designator_Runway\", \n    assign_udf(\"lat\", \"lon\")\n)\n\n# Separamos en dos columnas el resultado\ndf_with_hp = df_with_hp.withColumn(\n    \"Designator\", F.col(\"Designator_Runway.Designator\")\n).withColumn(\n    \"Runway\", F.col(\"Designator_Runway.Runway\")\n)\ndf_with_hp = df_with_hp.drop(\"Designator_Runway\")","user":"jmarti32","dateUpdated":"2025-04-15T00:13:29+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1744638894021_1551622182","id":"20250414-135454_1876091336","dateCreated":"2025-04-14T13:54:54+0000","dateStarted":"2025-04-15T00:13:29+0000","dateFinished":"2025-04-15T00:13:31+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4129"},{"text":"%md\n#### 7. Combinamos con las categorías de turbulencia\n\n\n","user":"jmarti32","dateUpdated":"2025-04-15T00:13:31+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h4>7. Combinamos con las categorías de turbulencia</h4>\n\n</div>"}]},"apps":[],"jobName":"paragraph_1744639229625_-1151176781","id":"20250414-140029_94085708","dateCreated":"2025-04-14T14:00:29+0000","dateStarted":"2025-04-15T00:13:31+0000","dateFinished":"2025-04-15T00:13:31+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4130"},{"text":"%livy3.pyspark\n\ndf_with_hp_tc = df_with_hp.join(df_types, on=\"ICAO\", how=\"inner\")","user":"jmarti32","dateUpdated":"2025-04-15T00:13:31+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1744641901406_-87193037","id":"20250414-144501_424578019","dateCreated":"2025-04-14T14:45:01+0000","dateStarted":"2025-04-15T00:13:31+0000","dateFinished":"2025-04-15T00:13:32+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4131"},{"text":"%livy3.pyspark\ndfA = df_with_hp_tc","user":"jmarti32","dateUpdated":"2025-04-15T00:13:32+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1744648602098_323526891","id":"20250414-163642_1156605826","dateCreated":"2025-04-14T16:36:42+0000","dateStarted":"2025-04-15T00:13:32+0000","dateFinished":"2025-04-15T00:13:33+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4132"},{"text":"%md\n#### 8. Eliminamos todos los vuelos que no se les ha detectado en un punto de espera","user":"jmarti32","dateUpdated":"2025-04-15T00:13:33+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h4>8. Eliminamos todos los vuelos que no se les ha detectado en un punto de espera</h4>\n\n</div>"}]},"apps":[],"jobName":"paragraph_1744642161811_462752606","id":"20250414-144921_1899109159","dateCreated":"2025-04-14T14:49:21+0000","dateStarted":"2025-04-15T00:13:33+0000","dateFinished":"2025-04-15T00:13:33+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4133"},{"text":"%livy3.pyspark\n\nfrom pyspark.sql.functions import col, count, when\n\n# Filtramos solo los vuelos que alguna vez tuvieron un Designator no nulo\ndf_holding_count = df_with_hp_tc.groupBy(\"Callsign\").agg(\n    count(when(col(\"Designator\").isNotNull(), True)).alias(\"holding_count\")\n).filter(col(\"holding_count\") > 0)\n\n# Nos quedamos solo con los vuelos válidos (que pasaron por un holding point)\ndf_valid_callsigns = df_holding_count.select(\"Callsign\")\n\n# Unimos para mantener solo las filas de esos vuelos\ndf_valid_flights = df_with_hp_tc.join(df_valid_callsigns, on=\"Callsign\", how=\"inner\")","user":"jmarti32","dateUpdated":"2025-04-15T00:13:33+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1744642535628_-1557748439","id":"20250414-145535_463208782","dateCreated":"2025-04-14T14:55:35+0000","dateStarted":"2025-04-15T00:13:33+0000","dateFinished":"2025-04-15T00:13:34+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4134"},{"text":"%md\n#### 9. Nos quedamos con las posiciones desde que se le detecta en un punto de espera hasta la primera vez que se le detecta en el aire","user":"jmarti32","dateUpdated":"2025-04-15T00:13:34+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h4>9. Nos quedamos con las posiciones desde que se le detecta en un punto de espera hasta la primera vez que se le detecta en el aire</h4>\n\n</div>"}]},"apps":[],"jobName":"paragraph_1744651348483_518866552","id":"20250414-172228_1410443714","dateCreated":"2025-04-14T17:22:28+0000","dateStarted":"2025-04-15T00:13:34+0000","dateFinished":"2025-04-15T00:13:34+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4135"},{"text":"%livy3.pyspark\nfrom pyspark.sql.window import Window\nfrom pyspark.sql.functions import min\n\n# Ventana por Callsign\nwindow_spec = Window.partitionBy(\"Callsign\")\n\n# Encontramos el primer timestamp en que el Designator no es nulo\ndf_with_first_holding = df_valid_flights.withColumn(\n    \"first_holding_time\",\n    min(when(col(\"Designator\").isNotNull(), col(\"Timestamp\"))).over(window_spec)\n)\n\n# Filtramos solo las filas en o después del primer punto de espera\ndf_from_hp = df_with_first_holding.filter(col(\"Timestamp\") >= col(\"first_holding_time\"))\n","user":"jmarti32","dateUpdated":"2025-04-15T00:13:34+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1744642835232_-969089573","id":"20250414-150035_1607170937","dateCreated":"2025-04-14T15:00:35+0000","dateStarted":"2025-04-15T00:13:34+0000","dateFinished":"2025-04-15T00:13:36+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4136"},{"text":"%livy3.pyspark\n\n# Encontramos el primer timestamp en que FlightStatus es 'airborne'\n\ndf_with_first_airborne = df_from_hp.withColumn(\n    \"first_airborne_time\",\n    F.min(F.when(F.col(\"Flight status\") == \"airborne\", F.col(\"Timestamp\"))).over(window_spec)\n)\n\n# Filtramos solo las filas en o después del primer estado airborne\ndf_takeoff_segment = df_with_first_airborne.filter(F.col(\"Timestamp\") <= F.col(\"first_airborne_time\"))\n","user":"jmarti32","dateUpdated":"2025-04-15T00:13:36+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1744651162136_473195976","id":"20250414-171922_806639087","dateCreated":"2025-04-14T17:19:22+0000","dateStarted":"2025-04-15T00:13:36+0000","dateFinished":"2025-04-15T00:13:37+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4137"},{"text":"%md\n#### 10. Creamos una columna que indique cuántas aeronaves hay situadas en puntos de espera de la misma pista que han llegado antes que la aeronave","user":"jmarti32","dateUpdated":"2025-04-15T00:13:37+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h4>10. Creamos una columna que indique cuántas aeronaves hay situadas en puntos de espera de la misma pista que han llegado antes que la aeronave</h4>\n\n</div>"}]},"apps":[],"jobName":"paragraph_1744643514470_-478470210","id":"20250414-151154_1332773899","dateCreated":"2025-04-14T15:11:54+0000","dateStarted":"2025-04-15T00:13:37+0000","dateFinished":"2025-04-15T00:13:37+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4138"},{"text":"%livy3.pyspark\n# CARMEN","user":"jmarti32","dateUpdated":"2025-04-15T00:13:37+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1744643531928_1453415397","id":"20250414-151211_1276686536","dateCreated":"2025-04-14T15:12:11+0000","dateStarted":"2025-04-15T00:13:37+0000","dateFinished":"2025-04-15T00:13:38+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4139"},{"text":"%md\n#### 11. Combinamos con los mensajes de velocidad","user":"jmarti32","dateUpdated":"2025-04-15T00:13:38+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h4>11. Combinamos con los mensajes de velocidad</h4>\n\n</div>"}]},"apps":[],"jobName":"paragraph_1744643570581_-2091060053","id":"20250414-151250_2076060658","dateCreated":"2025-04-14T15:12:50+0000","dateStarted":"2025-04-15T00:13:38+0000","dateFinished":"2025-04-15T00:13:38+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4140"},{"text":"%livy3.pyspark\n\n# Merge de posiciones y velocidades\nTOLERANCE_VELOCITY_ASSIGNMENT = 1  # 1 segundo\ndf_takeoff_segment = df_takeoff_segment.withColumn(\"Timestamp_sec\", F.unix_timestamp(\"Timestamp\"))\ndf_speed = df_speed.withColumn(\"Timestamp_sec\", F.unix_timestamp(\"Timestamp (date)\"))\n\ndf_speed = df_speed.withColumnRenamed(\"Timestamp_sec\", \"Timestamp_sec_speed\") \\\n                       .withColumnRenamed(\"Timestamp (date)\", \"Timestamp_speed\") \\\n                       .withColumnRenamed(\"Flight status\", \"Flight status Speed\")\n\ndf_with_velocities = df_takeoff_segment.join(df_speed, on=\"ICAO\", how=\"inner\").filter(\n    F.abs(df_takeoff_segment[\"Timestamp_sec\"] - df_speed[\"Timestamp_sec_speed\"]) <= TOLERANCE_VELOCITY_ASSIGNMENT\n)\n\ndf_with_velocities = df_with_velocities.drop(\"Timestamp_sec\", \"Timestamp_sec_speed\", \"Timestamp_speed\", \"Flight status Speed\")\ndf_with_velocities = df_with_velocities.dropDuplicates([\"ICAO\", \"Timestamp\"])","user":"jmarti32","dateUpdated":"2025-04-15T00:13:38+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1744643563479_268719750","id":"20250414-151243_284789266","dateCreated":"2025-04-14T15:12:43+0000","dateStarted":"2025-04-15T00:13:38+0000","dateFinished":"2025-04-15T00:13:39+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4141"},{"text":"%md\n\n#### 12. Filtramos para quedarnos solo con las aeronaves que en algún momento se paran en un punto de espera y recalculamos primer timestamp\n","user":"jmarti32","dateUpdated":"2025-04-15T00:13:39+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h4>12. Filtramos para quedarnos solo con las aeronaves que en algún momento se paran en un punto de espera y recalculamos primer timestamp</h4>\n\n</div>"}]},"apps":[],"jobName":"paragraph_1744649407727_1778553917","id":"20250414-165007_1912792647","dateCreated":"2025-04-14T16:50:07+0000","dateStarted":"2025-04-15T00:13:39+0000","dateFinished":"2025-04-15T00:13:39+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4142"},{"text":"%livy3.pyspark\n\n# Filtrar los callsigns con velocidad 0 y punto de espera no nulo\ndf_callsigns_zero_speed = df_with_velocities.filter(\n    (col(\"Speed\") == 0) & \n    (col(\"Designator\").isNotNull())\n).select(\"ICAO\").distinct()\n\n# Nos quedamos solo con estos vuelos\ndf_important_takeoffs = df_with_velocities.join(\n    df_callsigns_zero_speed,\n    on=\"ICAO\",\n    how=\"inner\" \n)","user":"jmarti32","dateUpdated":"2025-04-15T00:13:39+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1744646081594_-1444603631","id":"20250414-155441_1006143277","dateCreated":"2025-04-14T15:54:41+0000","dateStarted":"2025-04-15T00:13:40+0000","dateFinished":"2025-04-15T00:13:41+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4143"},{"text":"%livy3.pyspark\n# Ventana por Callsign\nwindow_spec = Window.partitionBy(\"Callsign\")\n\n# Encontramos el primer timestamp en que el Designator no es nulo\ndf_important_takeoffs = df_important_takeoffs.withColumn(\n    \"first_holding_time\",\n    min(when(col(\"Designator\").isNotNull() & (F.col(\"Speed\") == 0), col(\"Timestamp\"))).over(window_spec)\n)\n\n# Filtramos solo las filas en o después del primer punto de espera\ndf_important_takeoffs = df_important_takeoffs.filter(col(\"Timestamp\") >= col(\"first_holding_time\"))\n","user":"jmarti32","dateUpdated":"2025-04-15T00:13:41+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1744651871580_-1568495225","id":"20250414-173111_1375049952","dateCreated":"2025-04-14T17:31:11+0000","dateStarted":"2025-04-15T00:13:41+0000","dateFinished":"2025-04-15T00:13:42+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4144"},{"text":"%md\n#### 13. Calculamos tiempos de espera","user":"jmarti32","dateUpdated":"2025-04-15T00:13:42+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h4>13. Calculamos tiempos de espera</h4>\n\n</div>"}]},"apps":[],"jobName":"paragraph_1744646328816_1691077890","id":"20250414-155848_1717078904","dateCreated":"2025-04-14T15:58:48+0000","dateStarted":"2025-04-15T00:13:42+0000","dateFinished":"2025-04-15T00:13:42+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4145"},{"text":"%livy3.pyspark\n\n# Agrupar por identificador de vuelo\ndf_grouped = df_important_takeoffs.groupBy(\"Callsign\") \\\n                .agg(\n                    F.first(\"Designator\", ignorenulls=True).alias(\"Designator\"),\n                    F.first(\"Runway\", ignorenulls=True).alias(\"Runway\"),\n                    F.first(\"ICAO\", ignorenulls=True).alias(\"ICAO\"),\n                    F.first(\"lat\", ignorenulls=True).alias(\"lat\"),\n                    F.first(\"lon\", ignorenulls=True).alias(\"lon\"),\n                    F.first(\"TurbulenceCategory\", ignorenulls=True).alias(\"TurbulenceCategory\"),\n                    F.first(\"first_holding_time\").alias(\"first_holding_time\"),\n                    F.first(\"first_airborne_time\").alias(\"first_airborne_time\")\n                )\n\n\n# Calculamos los tiempos de espera\ndfB = df_grouped.withColumn(\"takeoff time\", \n                   (F.unix_timestamp(\"first_airborne_time\") - F.unix_timestamp(\"first_holding_time\"))\n                   .cast(\"double\"))\n","user":"jmarti32","dateUpdated":"2025-04-15T00:13:42+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1744651671975_1968703929","id":"20250414-172751_676450239","dateCreated":"2025-04-14T17:27:51+0000","dateStarted":"2025-04-15T00:13:42+0000","dateFinished":"2025-04-15T00:13:43+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4146"},{"text":"\n%md\n#### 14. Con dataframe A, creamos otro dataframe que indique cada 10s qué pistas y puntos de espera están ocupados → dataframe C","user":"jmarti32","dateUpdated":"2025-04-15T00:13:43+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h4>14. Con dataframe A, creamos otro dataframe que indique cada 10s qué pistas y puntos de espera están ocupados → dataframe C</h4>\n\n</div>"}]},"apps":[],"jobName":"paragraph_1744651633654_1663457884","id":"20250414-172713_1509642100","dateCreated":"2025-04-14T17:27:13+0000","dateStarted":"2025-04-15T00:13:43+0000","dateFinished":"2025-04-15T00:13:43+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4147"},{"text":"%livy3.pyspark\nimport pyspark.sql.functions as F\n\n# Redondear el timestamp a bloques de 10 segundos\n# La columna time_10s va a contener timestamps redondeados a bloques de 10 segundos en formato UNIX\ndfA = dfA.withColumn(\"time_10s\", (F.ceil(F.col(\"Timestamp\").cast(\"long\") / 10).cast(\"long\") * 10))\ndfA = dfA.withColumn(\"time_10s\", F.from_unixtime(F.col(\"time_10s\")))\n\n# Obtenemos los puntos de espera ocupados en cada intervalo\n# collect_set(): Agrupa todos los valores únicos de una columna (en este caso \"Designator\") dentro de cada grupo definido por un groupBy() o window y devuelve una lista sin duplicados\ndfA_holding_points = dfA.groupBy(\"time_10s\")\\\n    .agg(F.collect_set(\"Designator\").alias(\"occupied_holding_points\"))\n\nRUNWAYS = [\n    { \"type\": \"Feature\", \"properties\": { \"Runway\": \"36R/18L\" }, \"geometry\": { \"type\": \"Polygon\", \"coordinates\": [ [ [ -3.560314698993372, 40.536214953564219 ], [ -3.560115619892884, 40.499859371026062 ], [ -3.558758924220036, 40.499866800139706 ], [ -3.558958003320524, 40.536222382677863 ], [ -3.560314698993372, 40.536214953564219 ] ] ] } },\n    { \"type\": \"Feature\", \"properties\": { \"Runway\": \"32R/14L\" }, \"geometry\": { \"type\": \"Polygon\", \"coordinates\": [ [ [ -3.560616443164626, 40.49648882920043 ], [ -3.530233771171787, 40.466560555412769 ], [ -3.529390530746063, 40.467416598679677 ], [ -3.559773202738903, 40.49734487246733 ], [ -3.560616443164626, 40.49648882920043 ] ] ] } },\n    { \"type\": \"Feature\", \"properties\": { \"Runway\": \"36L/18R\" }, \"geometry\": { \"type\": \"Polygon\", \"coordinates\": [ [ [ -3.575312220900675, 40.533035679421005 ], [ -3.575065318943644, 40.492052937902109 ], [ -3.574163865545885, 40.492058368739578 ], [ -3.574410767502916, 40.533041110258473 ], [ -3.575312220900675, 40.533035679421005 ] ] ] } },\n    { \"type\": \"Feature\", \"properties\": { \"Runway\": \"32L/14R\" }, \"geometry\": { \"type\": \"Polygon\", \"coordinates\": [ [ [ -3.545264836113798, 40.455701584425526 ], [ -3.576990231488946, 40.486626436878893 ], [ -3.577924321488386, 40.485668166355438 ], [ -3.546198926113238, 40.454743313902071 ], [ -3.545264836113798, 40.455701584425526 ] ] ] } }\n]\n\nRUNWAY_POLYGONS = {\n    r[\"properties\"][\"Runway\"]: r[\"geometry\"][\"coordinates\"][0]\n    for r in RUNWAYS\n}\n\ndef point_in_polygon(lat, lon, polygon):\n    \"\"\"\n    lat, lon: coordenadas del punto\n    polygon: lista de coordenadas [(lon1, lat1), (lon2, lat2), ...] del polígono (ojo al orden lon/lat)\n    \"\"\"\n    num = len(polygon)\n    j = num - 1\n    inside = False\n\n    for i in range(num):\n        xi, yi = polygon[i]\n        xj, yj = polygon[j]\n        if ((yi > lat) != (yj > lat)) and \\\n           (lon < (xj - xi) * (lat - yi) / (yj - yi + 1e-9) + xi):\n            inside = not inside\n        j = i\n\n    return inside\n\n# Obtenemos las pistas ocupadas (geométricamente)\n\nfrom pyspark.sql.functions import udf\nfrom pyspark.sql.types import BooleanType, StringType\n\ndef get_runway_for_point(lat, lon):\n    for runway, polygon in RUNWAY_POLYGONS.items():\n        if point_in_polygon(lat, lon, polygon):\n            return runway\n    return None  # si no está en ninguna pista\n    \nget_runway_udf = udf(lambda lat, lon: get_runway_for_point(lat, lon), StringType())","user":"jmarti32","dateUpdated":"2025-04-15T00:13:43+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1744653825124_-258146557","id":"20250414-180345_154875765","dateCreated":"2025-04-14T18:03:45+0000","dateStarted":"2025-04-15T00:13:43+0000","dateFinished":"2025-04-15T00:13:44+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4148"},{"text":"%livy3.pyspark\n\ndfA = dfA.withColumn(\"RunwayFromPosition\", get_runway_udf(\"lat\", \"lon\"))\n\n# Pistas ocupadas por cada intervalo\ndfA_runways = dfA.groupBy(\"time_10s\")\\\n    .agg(F.collect_set(\"RunwayFromPosition\").alias(\"occupied_runways\"))\n\nstatus_by_interval = dfA_holding_points.join(dfA_runways, on=\"time_10s\")\n\nRUNWAY_NAMES = [\n    r[\"properties\"][\"Runway\"]\n    for r in RUNWAYS\n]\n\nHP_NAMES = [\n    hp[0]\n    for hp in holding_points\n]\n\n# Generamos las columnas booleanas para puntos de espera\nfor hp in HP_NAMES:\n    status_by_interval = status_by_interval.withColumn(f\"{hp}\", F.array_contains(F.col(\"occupied_holding_points\"), hp))\n    \n# Y para las pistas\nfor rw in RUNWAY_NAMES:\n    safe_rw = rw.replace(\"/\", \"_\")  # Evita caracteres problemáticos en nombres de columna\n    status_by_interval = status_by_interval.withColumn(f\"{safe_rw}\", F.array_contains(F.col(\"occupied_runways\"), rw))\n\nstatus_by_interval_final = status_by_interval.drop(\"occupied_holding_points\", \"occupied_runways\")","user":"jmarti32","dateUpdated":"2025-04-15T00:13:44+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1744654729727_-2055133454","id":"20250414-181849_763197461","dateCreated":"2025-04-14T18:18:49+0000","dateStarted":"2025-04-15T00:13:44+0000","dateFinished":"2025-04-15T00:13:45+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4149"},{"text":"%livy3.pyspark\ndfC = status_by_interval_final","user":"jmarti32","dateUpdated":"2025-04-15T00:13:46+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1744655311756_-1600627984","id":"20250414-182831_2130204595","dateCreated":"2025-04-14T18:28:31+0000","dateStarted":"2025-04-15T00:13:46+0000","dateFinished":"2025-04-15T00:13:47+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4150"},{"text":"%md\n#### 15. Con dataframe A, creamos otro dataframe que indique todos los despegues / aterrizajes por pista, debe incluir el timestamp y la categoría de turbulencia del avión","user":"jmarti32","dateUpdated":"2025-04-15T00:13:47+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h4>15. Con dataframe A, creamos otro dataframe que indique todos los despegues / aterrizajes por pista, debe incluir el timestamp y la categoría de turbulencia del avión</h4>\n\n</div>"}]},"apps":[],"jobName":"paragraph_1744648094383_171693971","id":"20250414-162814_886900227","dateCreated":"2025-04-14T16:28:14+0000","dateStarted":"2025-04-15T00:13:47+0000","dateFinished":"2025-04-15T00:13:47+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4151"},{"text":"%livy3.pyspark\n\nfrom pyspark.sql.window import Window\nfrom pyspark.sql import functions as F\n\nwindow_spec = Window.partitionBy(\"ICAO\").orderBy(\"Timestamp\")\n\ndfA = dfA.withColumn(\"Runway\", F.coalesce(\"Runway\", \"RunwayFromPosition\"))\ndfA = dfA.withColumn(\"prev_status\", F.lag(\"Flight status\").over(window_spec))\n\ndfD = dfA.filter(\n    ((F.col(\"Flight status\") == \"airborne\") & (F.col(\"prev_status\") == \"on-ground\")) |\n    ((F.col(\"Flight status\") == \"on-ground\") & (F.col(\"prev_status\") == \"airborne\"))\n).withColumn(\n    \"Event\",\n    F.when(F.col(\"Flight status\") == \"airborne\", F.lit(\"takeoff\"))\n     .when(F.col(\"Flight status\") == \"on-ground\", F.lit(\"landing\"))\n)\n\n\ndfD = dfD.select(\"Runway\", \"Timestamp\", \"TurbulenceCategory\", \"Event\")\n\ndfD = dfD.filter(F.col(\"Runway\").isNotNull())","user":"jmarti32","dateUpdated":"2025-04-15T00:13:47+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1744648087866_568589519","id":"20250414-162807_1213175665","dateCreated":"2025-04-14T16:28:07+0000","dateStarted":"2025-04-15T00:13:47+0000","dateFinished":"2025-04-15T00:13:48+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4152"},{"text":"%md\n#### 16. Agrupamos D por minuto para conseguir tasa de despegues y de aterrizajes por minuto","user":"jmarti32","dateUpdated":"2025-04-15T00:13:48+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h4>16. Agrupamos D por minuto para conseguir tasa de despegues y de aterrizajes por minuto</h4>\n\n</div>"}]},"apps":[],"jobName":"paragraph_1744648502595_1311595804","id":"20250414-163502_299231904","dateCreated":"2025-04-14T16:35:02+0000","dateStarted":"2025-04-15T00:13:48+0000","dateFinished":"2025-04-15T00:13:48+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4153"},{"text":"%livy3.pyspark\n\nfrom pyspark.sql.functions import count, when\n\ndfE = dfD.withColumn(\n    \"Minute\", \n    F.from_unixtime(\n        F.ceil(F.unix_timestamp(F.col(\"Timestamp\")) / 60) * 60\n    ).cast(\"timestamp\")\n) \\\n.groupBy(\"Minute\") \\\n.agg(\n    count(when(F.col(\"Event\") == \"takeoff\", True)).alias(\"last min takeoffs\"),\n    count(when(F.col(\"Event\") == \"landing\", True)).alias(\"last min landings\")\n)","user":"jmarti32","dateUpdated":"2025-04-15T00:13:48+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1744648495576_1307618135","id":"20250414-163455_241479774","dateCreated":"2025-04-14T16:34:55+0000","dateStarted":"2025-04-15T00:13:48+0000","dateFinished":"2025-04-15T00:13:49+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4154"},{"text":"%md\n#### 17. Combinamos B con C, D y E","user":"jmarti32","dateUpdated":"2025-04-15T00:13:49+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h4>17. Combinamos B con C, D y E</h4>\n\n</div>"}]},"apps":[],"jobName":"paragraph_1744656347175_-715600775","id":"20250414-184547_653222813","dateCreated":"2025-04-14T18:45:47+0000","dateStarted":"2025-04-15T00:13:49+0000","dateFinished":"2025-04-15T00:13:49+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4155"},{"text":"%livy3.pyspark\n\nfrom pyspark import StorageLevel\n\ndfA.persist(StorageLevel.MEMORY_AND_DISK)\ndfB.persist(StorageLevel.MEMORY_AND_DISK)\ndfC.persist(StorageLevel.MEMORY_AND_DISK)\ndfD.persist(StorageLevel.MEMORY_AND_DISK)\ndfE.persist(StorageLevel.MEMORY_AND_DISK)","user":"jmarti32","dateUpdated":"2025-04-15T00:13:49+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"DataFrame[Minute: timestamp, last min takeoffs: bigint, last min landings: bigint]"}]},"apps":[],"jobName":"paragraph_1744656782251_860257598","id":"20250414-185302_1994718901","dateCreated":"2025-04-14T18:53:02+0000","dateStarted":"2025-04-15T00:13:49+0000","dateFinished":"2025-04-15T00:13:51+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4156"},{"text":"%livy3.pyspark\n\nfrom pyspark.sql.functions import col, unix_timestamp, from_unixtime, round\n\n# Redondeamos a múltiplos de 10 segundos\ndfB = dfB.withColumn(\n    \"time_10s\",\n    from_unixtime((unix_timestamp(\"first_holding_time\") / 10).cast(\"long\") * 10)\n)\n\n# Paso 2: Join con dfC\ndfF = dfB.join(dfC, on=\"time_10s\", how=\"inner\")","user":"jmarti32","dateUpdated":"2025-04-15T00:13:52+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1744656980248_-1743555101","id":"20250414-185620_1015873358","dateCreated":"2025-04-14T18:56:20+0000","dateStarted":"2025-04-15T00:13:52+0000","dateFinished":"2025-04-15T00:13:53+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4157"},{"text":"%livy3.pyspark\nfrom pyspark.sql.functions import date_trunc\n\n# Paso 1: Redondear a minuto\ndfF = dfF.withColumn(\n    \"Minute\",\n    date_trunc(\"minute\", col(\"first_holding_time\"))\n)\n\n# Paso 2: Join con dfE\ndfF = dfF.join(dfE, on=\"Minute\", how=\"inner\")","user":"jmarti32","dateUpdated":"2025-04-15T00:13:53+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1744657447330_197359298","id":"20250414-190407_868871070","dateCreated":"2025-04-14T19:04:07+0000","dateStarted":"2025-04-15T00:13:53+0000","dateFinished":"2025-04-15T00:13:54+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4158"},{"text":"%livy3.pyspark\n\nfrom pyspark.sql.window import Window\nfrom pyspark.sql.functions import col, last\nfrom pyspark.sql.functions import row_number\n\n# Paso 1: Creamos la window\nw = Window.partitionBy(\"Runway\").orderBy(\"Timestamp\").rangeBetween(Window.unboundedPreceding, Window.currentRow)\n\n# Paso 2: Renombramos Timestamp para evitar conflictos en el join\ndfD = dfD.withColumnRenamed(\"Timestamp\", \"event_timestamp\")\ndfD = dfD.withColumnRenamed(\"TurbulenceCategory\", \"last_event_turb_cat\")\ndfD = dfD.withColumnRenamed(\"Event\", \"last_event\")\n\n# Paso 3: Join de los dataframes en base a Runway y evento previo en el tiempo\ndf_combined = dfF.join(dfD, on=\"Runway\", how=\"left\") \\\n    .filter(col(\"event_timestamp\") < col(\"first_holding_time\"))\n\n# Paso 4: Usamos Window para quedarnos con la fila más reciente antes de `first_holding_time`\nw2 = Window.partitionBy(\"Callsign\", \"first_holding_time\", \"Runway\").orderBy(col(\"event_timestamp\").desc())\n\ndf_final = df_combined.withColumn(\"rank\", row_number().over(w2)) \\\n    .filter(col(\"rank\") == 1) \\\n    .drop(\"rank\")\n\ndf_final = df_final.withColumn(\n    \"time_since_last_event_seconds\",\n    unix_timestamp(\"first_holding_time\") - unix_timestamp(\"event_timestamp\")\n)\n","user":"jmarti32","dateUpdated":"2025-04-15T00:13:54+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1744658888610_1168011472","id":"20250414-192808_674177510","dateCreated":"2025-04-14T19:28:08+0000","dateStarted":"2025-04-15T00:13:54+0000","dateFinished":"2025-04-15T00:13:55+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4159"},{"text":"%md\n#### 19. Extraemos la hora, día de la semana y si es festivo o no","user":"jmarti32","dateUpdated":"2025-04-15T00:13:55+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h4>19. Extraemos la hora, día de la semana y si es festivo o no</h4>\n\n</div>"}]},"apps":[],"jobName":"paragraph_1744664117062_-403967384","id":"20250414-205517_1234165797","dateCreated":"2025-04-14T20:55:17+0000","dateStarted":"2025-04-15T00:13:55+0000","dateFinished":"2025-04-15T00:13:55+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4160"},{"text":"%livy3.pyspark\n# hora, dia de la semana y si es festivo o no\n\nfrom pyspark.sql.functions import udf\nfrom pyspark.sql.types import BooleanType\n\nimport json\nfrom pyspark.sql.functions import to_date, hour, date_format, udf\nfrom pyspark.sql.types import BooleanType\n\n# Lista en json de festivos en España y en la Comunidad de Madrid extraída en local (no está instalada la librería 'holidays' en Zepelin)\nholiday_list_json = [\n  {\n    \"date\": \"2024-01-01\",\n    \"name\": \"A\\u00f1o Nuevo\"\n  },\n  {\n    \"date\": \"2024-01-06\",\n    \"name\": \"Epifan\\u00eda del Se\\u00f1or\"\n  },\n  {\n    \"date\": \"2024-03-29\",\n    \"name\": \"Viernes Santo\"\n  },\n  {\n    \"date\": \"2024-05-01\",\n    \"name\": \"Fiesta del Trabajo\"\n  },\n  {\n    \"date\": \"2024-08-15\",\n    \"name\": \"Asunci\\u00f3n de la Virgen\"\n  },\n  {\n    \"date\": \"2024-10-12\",\n    \"name\": \"Fiesta Nacional de Espa\\u00f1a\"\n  },\n  {\n    \"date\": \"2024-11-01\",\n    \"name\": \"Todos los Santos\"\n  },\n  {\n    \"date\": \"2024-12-06\",\n    \"name\": \"D\\u00eda de la Constituci\\u00f3n Espa\\u00f1ola\"\n  },\n  {\n    \"date\": \"2024-12-25\",\n    \"name\": \"Natividad del Se\\u00f1or\"\n  },\n  {\n    \"date\": \"2024-03-28\",\n    \"name\": \"Jueves Santo\"\n  },\n  {\n    \"date\": \"2024-05-02\",\n    \"name\": \"Fiesta de la Comunidad de Madrid\"\n  },\n  {\n    \"date\": \"2024-07-25\",\n    \"name\": \"Santiago Ap\\u00f3stol\"\n  },\n  {\n    \"date\": \"2025-01-01\",\n    \"name\": \"A\\u00f1o Nuevo\"\n  },\n  {\n    \"date\": \"2025-01-06\",\n    \"name\": \"Epifan\\u00eda del Se\\u00f1or\"\n  },\n  {\n    \"date\": \"2025-04-18\",\n    \"name\": \"Viernes Santo\"\n  },\n  {\n    \"date\": \"2025-05-01\",\n    \"name\": \"Fiesta del Trabajo\"\n  },\n  {\n    \"date\": \"2025-08-15\",\n    \"name\": \"Asunci\\u00f3n de la Virgen\"\n  },\n  {\n    \"date\": \"2025-11-01\",\n    \"name\": \"Todos los Santos\"\n  },\n  {\n    \"date\": \"2025-12-06\",\n    \"name\": \"D\\u00eda de la Constituci\\u00f3n Espa\\u00f1ola\"\n  },\n  {\n    \"date\": \"2025-12-08\",\n    \"name\": \"Inmaculada Concepci\\u00f3n\"\n  },\n  {\n    \"date\": \"2025-12-25\",\n    \"name\": \"Natividad del Se\\u00f1or\"\n  },\n  {\n    \"date\": \"2025-04-17\",\n    \"name\": \"Jueves Santo\"\n  },\n  {\n    \"date\": \"2025-05-02\",\n    \"name\": \"Fiesta de la Comunidad de Madrid\"\n  },\n  {\n    \"date\": \"2025-07-25\",\n    \"name\": \"Santiago Ap\\u00f3stol\"\n  }\n]\n\n# Crear conjunto de fechas festivas (como strings \"yyyy-MM-dd\")\nholiday_dates = set(item[\"date\"] for item in holiday_list_json)\n\n# UDF para marcar si una fecha es festiva\nis_holiday_udf = udf(lambda d: d.strftime(\"%Y-%m-%d\") in holiday_dates, BooleanType())\n\n# Añadir columnas a dfE\ndf_final = df_final.withColumn(\"Hour\", hour(\"Minute\")) \\\n         .withColumn(\"Weekday\", date_format(\"Minute\", \"E\")) \\\n         .withColumn(\"Date\", to_date(\"Minute\")) \\\n         .withColumn(\"IsHoliday\", is_holiday_udf(\"Date\")) \\\n         .drop(\"Date\")","user":"jmarti32","dateUpdated":"2025-04-15T00:13:55+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1744668744525_-868419140","id":"20250414-221224_384390008","dateCreated":"2025-04-14T22:12:24+0000","dateStarted":"2025-04-15T00:13:55+0000","dateFinished":"2025-04-15T00:13:56+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4161"},{"text":"%md\n#### 20. Extraemos la aerolínea","user":"jmarti32","dateUpdated":"2025-04-15T00:13:56+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h4>20. Extraemos la aerolínea</h4>\n\n</div>"}]},"apps":[],"jobName":"paragraph_1744671738687_176608032","id":"20250414-230218_1655465274","dateCreated":"2025-04-14T23:02:18+0000","dateStarted":"2025-04-15T00:13:56+0000","dateFinished":"2025-04-15T00:13:56+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4162"},{"text":"%livy3.pyspark\nfrom pyspark.sql.functions import substring\n\ndf_final = df_final.withColumn(\"operator\", substring(\"Callsign\", 1, 3))","user":"jmarti32","dateUpdated":"2025-04-15T00:13:56+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1744671716851_-1938916483","id":"20250414-230156_1689013942","dateCreated":"2025-04-14T23:01:56+0000","dateStarted":"2025-04-15T00:13:56+0000","dateFinished":"2025-04-15T00:13:57+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4163"},{"text":"%md\n#### 21. Renombramos y reordenamos columnas","user":"jmarti32","dateUpdated":"2025-04-15T00:13:58+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h4>21. Renombramos y reordenamos columnas</h4>\n\n</div>"}]},"apps":[],"jobName":"paragraph_1744675075769_1963173351","id":"20250414-235755_1614154460","dateCreated":"2025-04-14T23:57:55+0000","dateStarted":"2025-04-15T00:13:58+0000","dateFinished":"2025-04-15T00:13:58+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4164"},{"text":"%livy3.pyspark\nfrom pyspark.sql import functions as F\n\n# Suponiendo que df es tu DataFrame original\ndf_final_clean = df_final.select(\n    F.col('takeoff time').alias('takeoff_time'),\n    F.col('ICAO').alias('icao'),\n    F.col('Callsign').alias('callsign'),\n    F.col('Designator').alias('holding_point'),\n    F.col('Runway').alias('runway'),\n    F.col('operator'),\n    F.col('TurbulenceCategory').alias('turbulence_category'),\n    F.col('lat'),\n    F.col('lon'),\n    F.col('last min takeoffs').alias('last_min_takeoffs'),\n    F.col('last_event'),\n    F.col('last min landings').alias('last_min_landings'),\n    F.col('last_event_turb_cat').alias('last_event_turb_cat'),\n    F.col('time_since_last_event_seconds'),\n    F.col('Hour').alias('hour'),\n    F.col('Weekday').alias('weekday'),\n    F.col('IsHoliday').alias('is_holiday'),\n    F.col('event_timestamp'),\n    F.col('first_holding_time'),\n    F.col('first_airborne_time'),\n    'Z1', 'KA6', 'KA8', 'K3', 'K2', 'K1', 'Y1', 'Y2', 'Y3', 'Y7', 'Z6', 'Z4', 'Z2', \n    'Z3', 'LF', 'L1', 'LA', 'LB', 'LC', 'LD', 'LE', '36R_18L', '32R_14L', '36L_18R', '32L_14R'\n    \n)\n","user":"jmarti32","dateUpdated":"2025-04-15T00:13:58+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1744675094287_1129048510","id":"20250414-235814_1558872810","dateCreated":"2025-04-14T23:58:14+0000","dateStarted":"2025-04-15T00:13:58+0000","dateFinished":"2025-04-15T00:13:59+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4165"},{"text":"%livy3.pyspark\ndf_final_clean.persist(StorageLevel.MEMORY_AND_DISK)","user":"jmarti32","dateUpdated":"2025-04-15T00:13:59+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"DataFrame[takeoff_time: double, icao: string, callsign: string, holding_point: string, runway: string, operator: string, turbulence_category: string, lat: float, lon: float, last_min_takeoffs: bigint, last_event: string, last_min_landings: bigint, last_event_turb_cat: string, time_since_last_event_seconds: bigint, hour: int, weekday: string, is_holiday: boolean, event_timestamp: timestamp, first_holding_time: timestamp, first_airborne_time: timestamp, Z1: boolean, KA6: boolean, KA8: boolean, K3: boolean, K2: boolean, K1: boolean, Y1: boolean, Y2: boolean, Y3: boolean, Y7: boolean, Z6: boolean, Z4: boolean, Z2: boolean, Z3: boolean, LF: boolean, L1: boolean, LA: boolean, LB: boolean, LC: boolean, LD: boolean, LE: boolean, 36R_18L: boolean, 32R_14L: boolean, 36L_18R: boolean, 32L_14R: boolean]"}]},"apps":[],"jobName":"paragraph_1744675666632_-1454284915","id":"20250415-000746_314505774","dateCreated":"2025-04-15T00:07:46+0000","dateStarted":"2025-04-15T00:13:59+0000","dateFinished":"2025-04-15T00:14:00+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4166"},{"text":"%livy3.pyspark\ndf_final_clean.show()","user":"jmarti32","dateUpdated":"2025-04-15T00:14:00+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1744668974088_-1242136355","id":"20250414-221614_1303771507","dateCreated":"2025-04-14T22:16:14+0000","dateStarted":"2025-04-15T00:14:00+0000","dateFinished":"2025-04-15T00:11:03+0000","status":"RUNNING","progressUpdateIntervalMs":500,"$$hashKey":"object:4167","errorMessage":""},{"text":"%livy3.pyspark\ndf_final_clean.printSchema()","user":"jmarti32","dateUpdated":"2025-04-15T00:11:03+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"root\n |-- takeoff_time: double (nullable = true)\n |-- icao: string (nullable = true)\n |-- callsign: string (nullable = true)\n |-- holding_point: string (nullable = true)\n |-- runway: string (nullable = true)\n |-- operator: string (nullable = true)\n |-- turbulence_category: string (nullable = true)\n |-- lat: float (nullable = true)\n |-- lon: float (nullable = true)\n |-- last_min_takeoffs: long (nullable = false)\n |-- last_event: string (nullable = true)\n |-- last_min_landings: long (nullable = false)\n |-- last_event_turb_cat: string (nullable = true)\n |-- time_since_last_event_seconds: long (nullable = true)\n |-- hour: integer (nullable = true)\n |-- weekday: string (nullable = true)\n |-- is_holiday: boolean (nullable = true)\n |-- event_timestamp: timestamp (nullable = true)\n |-- first_holding_time: timestamp (nullable = true)\n |-- first_airborne_time: timestamp (nullable = true)\n |-- Z1: boolean (nullable = false)\n |-- KA6: boolean (nullable = false)\n |-- KA8: boolean (nullable = false)\n |-- K3: boolean (nullable = false)\n |-- K2: boolean (nullable = false)\n |-- K1: boolean (nullable = false)\n |-- Y1: boolean (nullable = false)\n |-- Y2: boolean (nullable = false)\n |-- Y3: boolean (nullable = false)\n |-- Y7: boolean (nullable = false)\n |-- Z6: boolean (nullable = false)\n |-- Z4: boolean (nullable = false)\n |-- Z2: boolean (nullable = false)\n |-- Z3: boolean (nullable = false)\n |-- LF: boolean (nullable = false)\n |-- L1: boolean (nullable = false)\n |-- LA: boolean (nullable = false)\n |-- LB: boolean (nullable = false)\n |-- LC: boolean (nullable = false)\n |-- LD: boolean (nullable = false)\n |-- LE: boolean (nullable = false)\n |-- 36R_18L: boolean (nullable = false)\n |-- 32R_14L: boolean (nullable = false)\n |-- 36L_18R: boolean (nullable = false)\n |-- 32L_14R: boolean (nullable = false)"}]},"apps":[],"jobName":"paragraph_1744668983986_238052885","id":"20250414-221623_1004107204","dateCreated":"2025-04-14T22:16:23+0000","dateStarted":"2025-04-15T00:11:03+0000","dateFinished":"2025-04-15T00:11:04+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:4168"},{"text":"%livy3.pyspark\ndf_final_clean.write.parquet(\"/data/proyecto2/outputs/iberIA/processed/2024_11_11.parquet\")","user":"jmarti32","dateUpdated":"2025-04-15T00:11:05+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"path hdfs://cloudera2.internal.fdi.ucm.es:8020/data/proyecto2/outputs/iberIA/processed/2024_11_11.parquet already exists.\nTraceback (most recent call last):\n  File \"/opt/cloudera/parcels/SPARK3-3.3.2.3.3.7191000.6-1-1.p0.62141200/lib/spark3/python/lib/pyspark.zip/pyspark/sql/readwriter.py\", line 1140, in parquet\n    self._jwrite.parquet(path)\n  File \"/opt/cloudera/parcels/SPARK3-3.3.2.3.3.7191000.6-1-1.p0.62141200/lib/spark3/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py\", line 1321, in __call__\n    return_value = get_return_value(\n  File \"/opt/cloudera/parcels/SPARK3-3.3.2.3.3.7191000.6-1-1.p0.62141200/lib/spark3/python/lib/pyspark.zip/pyspark/sql/utils.py\", line 196, in deco\n    raise converted from None\npyspark.sql.utils.AnalysisException: path hdfs://cloudera2.internal.fdi.ucm.es:8020/data/proyecto2/outputs/iberIA/processed/2024_11_11.parquet already exists.\n"}]},"apps":[],"jobName":"paragraph_1744669034208_-217392933","id":"20250414-221714_1535166878","dateCreated":"2025-04-14T22:17:14+0000","dateStarted":"2025-04-15T00:11:05+0000","dateFinished":"2025-04-15T00:11:06+0000","status":"ERROR","progressUpdateIntervalMs":500,"$$hashKey":"object:4169"},{"text":"%livy3.pyspark\n","user":"jmarti32","dateUpdated":"2025-04-15T00:04:38+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1744675478022_-415214046","id":"20250415-000438_2058241456","dateCreated":"2025-04-15T00:04:38+0000","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:4170"}],"name":"pipeline","id":"2KT7K2DYT","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"angular:shared_process":[],"livy3:shared_process":[],"livy:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}