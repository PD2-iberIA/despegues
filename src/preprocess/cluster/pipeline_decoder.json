{"paragraphs":[{"text":"%livy3.pyspark\nsc.addPyFile(\"hdfs:///data/proyecto2/paquetesPython.tgz\")\n\nfrom pyspark.sql.functions import col, to_timestamp\nimport pyModeS as pms","user":"jmarti32","dateUpdated":"2025-04-21T21:25:52+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"java.lang.InterruptedException: sleep interrupted"}]},"apps":[],"jobName":"paragraph_1744814774143_-592679936","id":"20250416-135653_1641376600","dateCreated":"2025-04-16T14:46:14+0000","status":"ABORT","errorMessage":"java.lang.InterruptedException: sleep interrupted\n\tat java.base/java.lang.Thread.sleep(Native Method)\n\tat org.apache.zeppelin.notebook.Paragraph.execute(Paragraph.java:361)\n\tat org.apache.zeppelin.notebook.Note.run(Note.java:683)\n\tat org.apache.zeppelin.socket.NotebookServer.persistAndExecuteSingleParagraph(NotebookServer.java:1881)\n\tat org.apache.zeppelin.socket.NotebookServer.runAllParagraphs(NotebookServer.java:1745)\n\tat org.apache.zeppelin.socket.NotebookServer.onMessage(NotebookServer.java:268)\n\tat org.apache.zeppelin.socket.NotebookSocket.onWebSocketText(NotebookSocket.java:59)\n\tat org.eclipse.jetty.websocket.common.events.JettyListenerEventDriver.onTextMessage(JettyListenerEventDriver.java:296)\n\tat org.eclipse.jetty.websocket.common.message.SimpleTextMessage.messageComplete(SimpleTextMessage.java:69)\n\tat org.eclipse.jetty.websocket.common.events.AbstractEventDriver.appendMessage(AbstractEventDriver.java:67)\n\tat org.eclipse.jetty.websocket.common.events.JettyListenerEventDriver.onTextFrame(JettyListenerEventDriver.java:235)\n\tat org.eclipse.jetty.websocket.common.events.AbstractEventDriver.incomingFrame(AbstractEventDriver.java:152)\n\tat org.eclipse.jetty.websocket.common.WebSocketSession.incomingFrame(WebSocketSession.java:326)\n\tat org.eclipse.jetty.websocket.common.extensions.AbstractExtension.nextIncomingFrame(AbstractExtension.java:148)\n\tat org.eclipse.jetty.websocket.common.extensions.compress.PerMessageDeflateExtension.nextIncomingFrame(PerMessageDeflateExtension.java:111)\n\tat org.eclipse.jetty.websocket.common.extensions.compress.CompressExtension.forwardIncoming(CompressExtension.java:169)\n\tat org.eclipse.jetty.websocket.common.extensions.compress.PerMessageDeflateExtension.incomingFrame(PerMessageDeflateExtension.java:90)\n\tat org.eclipse.jetty.websocket.common.extensions.ExtensionStack.incomingFrame(ExtensionStack.java:202)\n\tat org.eclipse.jetty.websocket.common.Parser.notifyFrame(Parser.java:225)\n\tat org.eclipse.jetty.websocket.common.Parser.parseSingleFrame(Parser.java:259)\n\tat org.eclipse.jetty.websocket.common.io.AbstractWebSocketConnection.onFillable(AbstractWebSocketConnection.java:459)\n\tat org.eclipse.jetty.websocket.common.io.AbstractWebSocketConnection.onFillable(AbstractWebSocketConnection.java:440)\n\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\n\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\n\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\n\tat java.base/java.lang.Thread.run(Thread.java:834)\n","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:169"},{"text":"%livy3.pyspark\nimport json\nimport os\n\n# Posición del radar (lat, lon)\nRADAR_POSITION = (40.51, -3.53)\n\n# Pistas con sus orientaciones (lat, lon, orient)\nRUNWAY_1 = {\n    'position': (40.463, -3.554),\n    'orientation': '32L/14R'\n}\nRUNWAY_2 = {\n    'position': (40.473, -3.536),\n    'orientation': '32R/14L'\n}\nRUNWAY_3 = {\n    'position': (40.507, -3.574),\n    'orientation': '36L/18R'\n}\nRUNWAY_4 = {\n    'position': (40.507, -3.559),\n    'orientation': '36R/18L'\n}","user":"jmarti32","dateUpdated":"2025-04-16T14:46:14+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1744814774143_1711537502","id":"20250416-135707_153671602","dateCreated":"2025-04-16T14:46:14+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:170"},{"text":"%livy3.pyspark\nfrom pyspark.sql.functions import when, col\nfrom pyspark.sql import DataFrame\nimport numpy as np\n\n\ndef separateCoordinates(coord):\n    \"\"\"Obtiene la latitud y longitud a partir de la tupla de posición.\n    \n    Args:\n        coord (tuple): Tupla de coordenadas.\n\n    Returns:\n        dict: Latitud y longitud separadas.\n    \"\"\"\n    return {\"lat\": coord[0], \"lon\": coord[1]}\n\ndef separateVelocity(velocity):\n    \"\"\"Separa los elementos de la tupla devuelta por la función `pms.adsb.velocity()`\n    \n    Args:\n        velocity (tuple): Tupla que contiene datos sobre la velocidad.\n    \n    Returns:\n        dict: Datos de velocidad separados.\n    \"\"\"\n    if velocity is None:\n        return {'Speed': None, 'Angle': None, 'Vertical rate': None, 'Speed type':None}\n    else:\n        return {'Speed': velocity[0], 'Angle': velocity[1], 'Vertical rate': velocity[2], 'Speed type': velocity[3]}\n\ndef processStaticAirTemperature(temperature):\n    \"\"\"Si la temperatura obtenida es una tupla de ceros se establece como nula ya que se trata de un error de inconsistencia.\n    Fuente: https://mode-s.org/pymodes/api/pyModeS.decoder.bds.bds44.html#pyModeS.decoder.bds.bds44.temp44\n    \n    Args:\n        temperature (tuple or float): Temperatura del aire.\n\n    Returns:\n        (float or nan): Valor de la temperatura.\n    \"\"\"\n    if temperature == (0.0, 0.0):\n        temperature = np.nan\n    return temperature\n\ndef string_to_nan_spark(df: DataFrame) -> DataFrame:\n    \"\"\"Transforma todos los strings 'nan' o 'None' de un DataFrame de Spark a nulos.\n\n    Args:\n        df (DataFrame): DataFrame de Spark.\n\n    Returns:\n        DataFrame: DataFrame con los valores nulos en su tipo correcto.\n    \"\"\"\n    for column in df.columns:\n        df = df.withColumn(column, when(col(column).isin(\"nan\", \"None\"), None).otherwise(col(column)))\n    return df\n\n\ndef extract_days_of_the_week(df: DataFrame, col: str = 'Timestamp (date)') -> DataFrame:\n    \"\"\"Crea una nueva columna 'day_of_week' con las tres primeras letras del día de la semana.\n\n    Args:\n        df (DataFrame): DataFrame de Spark.\n        col (str): Nombre de la columna de fecha.\n\n    Returns:\n        DataFrame: DataFrame con la nueva columna 'day_of_week'.\n    \"\"\"\n    return df.withColumn(\"day_of_week\", date_format(col, \"EEE\"))\n\n\ndef extract_hour(df: DataFrame, col: str = 'Timestamp (date)') -> DataFrame:\n    \"\"\"Asegura que la columna de fecha está en formato timestamp y extrae la hora en una nueva columna 'hour'.\n\n    Args:\n        df (DataFrame): DataFrame de Spark.\n        col (str): Nombre de la columna de fecha.\n\n    Returns:\n        DataFrame: DataFrame con la nueva columna 'hour'.\n    \"\"\"\n    df = df.withColumn(col, to_timestamp(col))\n    return df.withColumn(\"hour\", hour(col))\n\n\ndef haversine(lat1, lon1, lat2, lon2):\n    \"\"\"Calcula la distancia entre dos puntos. Para ello utilizamos la fórmula de Haversine.\n    \n    Parámetros:\n        lat1, lon1 (float): Coordenadas del punto 1.\n        lat2, lon2 (float): Coordenadas del punto 2.\n\n    Devuelve:\n        (float): Distancia entre los dos puntos (km).\n    \"\"\"\n    EARTH_RADIUS = 6378 # radio de la Tierra (km)\n\n    phi1, phi2 = np.radians(lat1), np.radians(lat2)\n    delta_phi = np.radians(lat2 - lat1)\n    delta_lambda = np.radians(lon2 - lon1)\n\n    a = np.sin(delta_phi / 2)**2 + np.cos(phi1) * np.cos(phi2) * np.sin(delta_lambda / 2)**2\n    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n    distance = EARTH_RADIUS * c # km\n    return distance\n\ndef knots_to_kmh(speed_knots):\n    \"\"\"Transforma una velocidad de nudos (knots) a km/h.\n\n    Parámetros:\n        speed_knots (float): Velocidad en nudos.\n    \n    Devuelve:\n        (float): Velocidad en km/h.\n    \"\"\"\n    return speed_knots * 1.852 if pd.notna(speed_knots) else None\n","user":"jmarti32","dateUpdated":"2025-04-21T21:07:43+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1744814774144_-111568401","id":"20250416-135714_1426082362","dateCreated":"2025-04-16T14:46:14+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:171"},{"text":"%livy3.pyspark\nfrom collections import defaultdict\nfrom datetime import datetime\nimport base64\nfrom enum import Enum\nimport numpy as np\n\n\nclass MessageType(Enum):\n    \"\"\"\n    Enumerado para los diferentes tipos de mensajes que pueden ser procesados.\n\n    Los tipos de mensaje incluyen:\n        ALTITUDE: Mensajes relacionados con la altitud.\n        IDENTITY: Mensajes de identidad.\n        ADS_B: Mensajes ADS-B.\n        MODE_S: Mensajes de modo S.\n        NONE: Tipo de mensaje no reconocido.\n    \"\"\"\n    ALTITUDE = \"ALTITUDE\"\n    IDENTITY = \"IDENTITY\"\n    ADS_B = \"ADS_B\"\n    MODE_S = \"MODE_S\"\n    NONE = \"NONE\"\n\n\nclass Decoder:\n    \"\"\"\n    Clase para procesar mensajes y extraer información relevante de los mismos.\n\n    Los métodos de esta clase son responsables de decodificar los mensajes, identificar su tipo,\n    y extraer información como la altitud, el código de identidad, la turbulencia, entre otros.\n    \"\"\"\n\n    ON_GROUND = \"on-ground\"\n    AIRBORNE = \"airborne\"\n    \n    # Diccionarios de mapeo para diferentes tipos de mensajes y estados\n\n    # Identifica qué tipo de mensaje se recibe\n    MAP_DF = defaultdict(lambda: [MessageType.NONE], {  \n        4: [MessageType.ALTITUDE],\n        5: [MessageType.IDENTITY],\n        17: [MessageType.ADS_B],\n        18: [MessageType.ADS_B],\n        20: [MessageType.MODE_S, MessageType.ALTITUDE],\n        21: [MessageType.MODE_S, MessageType.IDENTITY]\n    })\n\n    # Estado de vuelo del avión\n    MAP_CA = defaultdict(lambda: float('nan'), {\n        4: ON_GROUND,\n        5: AIRBORNE\n    })\n    \n    MAP_FS = defaultdict(lambda: float('nan'), {\n        0: AIRBORNE,\n        1: ON_GROUND,\n        2: AIRBORNE,\n        3: ON_GROUND\n    })\n\n    # Categorías de turbulencias\n    MAP_WTC = {\n        (4, 1): \"Light\",\n        (4, 2): \"Medium 1\",\n        (4, 3): \"Medium 2\",\n        (4, 5): \"Heavy\",\n    }\n\n    # Categorías de las aeronaves\n    MAP_AIRCRAFT_CATEGORY = {\n        (1, 0): 'Reserved',\n        (0, 0): 'No category information',\n        (2, 1): 'Surface emergency vehicle',\n        (2, 3): 'Surface service vehicle',\n        (2, 4): 'Ground obstruction',\n        (2, 5): 'Ground obstruction',\n        (2, 6): 'Ground obstruction',\n        (2, 7): 'Ground obstruction',\n        (3, 1): 'Glider, sailplane',\n        (3, 2): 'Lighter-than-air',\n        (3, 3): 'Parachutist, skydiver',\n        (3, 4): 'Ultralight, hang-glider, paraglider',\n        (3, 5): 'Reserved',\n        (3, 6): 'Unmanned aerial vehicle',\n        (3, 7): 'Space or transatmospheric vehicle',\n        (4, 1): 'Light (less than 7000 kg)',\n        (4, 2): 'Medium 1 (between 7000 kg and 34000 kg)',\n        (4, 3): 'Medium 2 (between 34000 kg to 136000 kg)',\n        (4, 4): 'High vortex aircraft',\n        (4, 5): 'Heavy (larger than 136000 kg)',\n        (4, 6): 'High performance (>5 g acceleration) and high speed (>400 kt)',\n        (4, 7): 'Rotorcraft',\n    }\n\n    @staticmethod\n    def processMessage(msg, tsKafka):\n        \"\"\"\n        Procesa un mensaje y extrae la información relevante.\n\n        Args:\n            msg (str): El mensaje en formato base64 a procesar.\n            tsKafka (int): La marca de tiempo de Kafka asociada al mensaje.\n\n        Returns:\n            dict: Un diccionario con la información extraída del mensaje.\n        \"\"\"\n        data = {}\n\n        # Procesa el timestamp\n        data[\"Timestamp (kafka)\"] = tsKafka\n        data[\"Timestamp (date)\"] = Decoder.kafkaToDate(tsKafka) \n        \n        # Transforma el mensaje a hexadecimal\n        msgHex = Decoder.base64toHex(msg)\n        \n        data[\"Message (base64)\"] = msg\n        data[\"Message (hex)\"] = msgHex\n        \n        # Información básica\n        data[\"ICAO\"] = Decoder.getICAO(msgHex)\n        downlinkFormat = Decoder.getDF(msgHex)\n        data[\"Downlink Format\"] = downlinkFormat\n        \n        # Información dependiente del DF\n        msgType = Decoder.MAP_DF[data[\"Downlink Format\"]]\n        data[\"Flight status\"] = Decoder.getFlightStatus(msgHex, msgType)\n\n        # Procesa según el tipo de mensaje\n        if Decoder.isADS_B(msgType):\n            data.update(Decoder.processADS_B(msgHex))\n        if Decoder.isMODE_S(msgType):\n            data.update(Decoder.processMODE_S(msgHex))\n        if Decoder.isALTITUDE(msgType):\n            data.update(Decoder.processALTITUDE(msgHex))\n        if Decoder.isIDENTITY(msgType):\n            data.update(Decoder.processIDENTITY(msgHex))\n            \n        return data\n    \n    @staticmethod\n    def kafkaToDate(tsKafka):\n        \"\"\"\n        Convierte un timestamp de Kafka a una fecha legible.\n    \n        Args:\n            tsKafka (str): El timestamp de Kafka en milisegundos con posibles comillas.\n    \n        Returns:\n            datetime: El timestamp convertido a un objeto datetime.\n        \"\"\"\n        if isinstance(tsKafka, str):\n            tsKafka = int(tsKafka.strip('\"'))  # Eliminar comillas y convertir a entero\n        return datetime.fromtimestamp(tsKafka / 1000)\n\n        \n    @staticmethod\n    def base64toHex(msg):\n        \"\"\"\n        Convierte un mensaje en base64 a formato hexadecimal.\n\n        Args:\n            msg (str): El mensaje en formato base64.\n\n        Returns:\n            str: El mensaje convertido a hexadecimal.\n        \"\"\"\n        return base64.b64decode(msg).hex().upper()\n    \n    @staticmethod\n    def getICAO(msg):\n        \"\"\"\n        Extrae el código ICAO del mensaje.\n\n        Args:\n            msg (str): El mensaje en formato hexadecimal.\n\n        Returns:\n            str: El código ICAO extraído del mensaje.\n        \"\"\"\n        return pms.icao(msg)\n    \n    @staticmethod\n    def getDF(msg):\n        \"\"\"\n        Obtiene el formato de downlink del mensaje.\n\n        Args:\n            msg (str): El mensaje en formato hexadecimal.\n\n        Returns:\n            int: El formato de downlink del mensaje.\n        \"\"\"\n        return pms.df(msg)\n    \n    @staticmethod\n    def isIDENTITY(msgType):\n        \"\"\"\n        Verifica si el tipo de mensaje es de tipo IDENTITY.\n\n        Args:\n            msgType (list): Lista de tipos de mensajes a verificar.\n\n        Returns:\n            bool: True si el mensaje es de tipo IDENTITY, False de lo contrario.\n        \"\"\"\n        return MessageType.IDENTITY in msgType\n    \n    @staticmethod\n    def isALTITUDE(msgType):\n        \"\"\"\n        Verifica si el tipo de mensaje es de tipo ALTITUDE.\n\n        Args:\n            msgType (list): Lista de tipos de mensajes a verificar.\n\n        Returns:\n            bool: True si el mensaje es de tipo ALTITUDE, False de lo contrario.\n        \"\"\"\n        return MessageType.ALTITUDE in msgType\n    \n    @staticmethod\n    def isADS_B(msgType):\n        \"\"\"\n        Verifica si el tipo de mensaje es de tipo ADS-B.\n\n        Args:\n            msgType (list): Lista de tipos de mensajes a verificar.\n\n        Returns:\n            bool: True si el mensaje es de tipo ADS-B, False de lo contrario.\n        \"\"\"\n        return MessageType.ADS_B in msgType\n    \n    @staticmethod\n    def isMODE_S(msgType):\n        \"\"\"\n        Verifica si el tipo de mensaje es de tipo MODE-S.\n\n        Args:\n            msgType (list): Lista de tipos de mensajes a verificar.\n\n        Returns:\n            bool: True si el mensaje es de tipo MODE-S, False de lo contrario.\n        \"\"\"\n        return MessageType.MODE_S in msgType\n    \n    @staticmethod\n    def processALTITUDE(msg):\n        \"\"\"\n        Procesa un mensaje de tipo ALTITUDE y extrae la altitud.\n\n        Args:\n            msg (str): El mensaje en formato hexadecimal.\n\n        Returns:\n            dict: Un diccionario con la altitud extraída.\n        \"\"\"\n        return {\"Altitude (ft)\": pms.common.altcode(msg)}\n    \n    @staticmethod\n    def processIDENTITY(msg):\n        \"\"\"\n        Procesa un mensaje de tipo IDENTITY y extrae el código de identificación.\n\n        Args:\n            msg (str): El mensaje en formato hexadecimal.\n\n        Returns:\n            dict: Un diccionario con el código de identificación extraído.\n        \"\"\"\n        return {\"Squawk code\": pms.common.idcode(msg)}\n    \n    @staticmethod\n    def getFlightStatus(msgHex, msgType):\n        \"\"\"\n        Obtiene el estado del vuelo desde el mensaje.\n\n        Args:\n            msgHex (str): El mensaje en formato hexadecimal.\n            msgType (list): El tipo de mensaje.\n\n        Returns:\n            str: El estado del vuelo (AIRBORNE o ON_GROUND).\n        \"\"\"\n        byteData = bytes.fromhex(msgHex)\n        status_byte = byteData[4]\n\n        if Decoder.isIDENTITY(msgType) or Decoder.isALTITUDE(msgType) or Decoder.isMODE_S(msgType):\n            fs = (status_byte >> 5) & 0b111  # bits 5-7\n            return Decoder.MAP_FS[fs]\n        \n        elif Decoder.isADS_B(msgType):\n            ca = (status_byte >> 5) & 0b111  # bits 5-7\n            return Decoder.MAP_CA[ca]\n        \n        return None\n    \n    @staticmethod\n    def getWakeTurbulenceCategory(msg):\n        \"\"\"\n        Determina la categoría de turbulencia del mensaje.\n\n        Args:\n            msg (str): El mensaje en formato base64.\n\n        Returns:\n            str: La categoría de turbulencia (Light, Medium, Heavy, etc.).\n        \"\"\"\n        msgHex = Decoder.base64toHex(msg)\n        byteData = bytes.fromhex(msgHex)  \n\n        typecode = pms.adsb.typecode(msg)\n        status_byte = byteData[4]\n        ca = (status_byte >> 5) & 0b111  # Bits 6-8\n\n        if typecode == 1:\n            ca = 0\n\n        return Decoder.MAP_AIRCRAFT_CATEGORY.get((typecode, ca))\n    \n    @staticmethod\n    def processADS_B(msg):\n        \"\"\"\n        Procesa un mensaje de tipo ADS-B y extrae la información relevante.\n\n        Args:\n            msg (str): El mensaje en formato hexadecimal.\n\n        Returns:\n            dict: Un diccionario con la información de ADS-B extraída.\n        \"\"\"\n        data = {}\n        \n        typecode = pms.adsb.typecode(msg)\n        \n        if not typecode:\n            return {}\n        \n        data[\"Typecode\"] = typecode\n        data['TurbulenceCategory'] = Decoder.getWakeTurbulenceCategory(msg)\n\n        if typecode <= 4:\n            data[\"Callsign\"] = pms.adsb.callsign(msg)\n\n        elif typecode == 19:\n            velocity = pms.adsb.velocity(msg) # maneja mensajes de tipo surface y airborne\n            data.update(separateVelocity(velocity))    \n            data[\"Speed heading\"] = pms.adsb.speed_heading(msg)\n            data[\"Flight status\"] = Decoder.AIRBORNE\n        \n        elif 5 <= typecode <= 22:\n            lat_ref, lon_ref = RADAR_POSITION\n\n            posRef = pms.adsb.position_with_ref(msg, lat_ref, lon_ref) # maneja mensajes de tipo surface y airborne\n            data[\"Position with ref (RADAR)\"] = posRef\n            data.update(separateCoordinates(posRef))\n        \n            # Surface - Typecode 5-8\n            if 5 <= typecode <= 8:\n                velocity = pms.adsb.velocity(msg)\n                data.update(separateVelocity(velocity))\n\n                if pms.adsb.surface_position_with_ref(msg, lat_ref, lon_ref):\n                    data[\"Flight status\"] = Decoder.ON_GROUND\n\n            # Airborne\n            elif pms.adsb.airborne_position_with_ref(msg, lat_ref, lon_ref):\n                data[\"Flight status\"] = Decoder.AIRBORNE\n\n            data[\"Altitude (ft)\"] = pms.adsb.altitude(msg)\n\n        return data\n\n    @staticmethod\n    def processMODE_S(msg):\n        \"\"\"\n        Procesa un mensaje de tipo MODE-S y extrae la información relevante.\n\n        Args:\n            msg (str): El mensaje en formato hexadecimal.\n\n        Returns:\n            dict: Un diccionario con la información de MODE-S extraída.\n        \"\"\"\n        data = {}\n        \n        bds = pms.bds.infer(msg, mrar=True)\n        data[\"BDS\"] = bds\n        \n        # BDS 1,0\n        if pms.bds.bds10.is10(msg):\n            data[\"Overlay capability\"] = pms.commb.ovc10(msg)\n            \n        # BDS 1,7\n        if pms.bds.bds17.is17(msg):\n            data[\"GICB capability\"] = pms.commb.cap17(msg)\n            \n        # BDS 2,0\n        if pms.bds.bds20.is20(msg):\n            data[\"Callsign\"] = pms.commb.cs20(msg)\n            \n        # BDS 4,0\n        if pms.bds.bds40.is40(msg):\n            data[\"MCP/FCU selected altitude (ft)\"] = pms.commb.selalt40mcp(msg)\n            data[\"FMS selected altitude (ft)\"] = pms.commb.selalt40fms(msg)\n            data[\"Barometric pressure (mb)\"] = pms.commb.p40baro(msg)\n        \n        # BDS 4,4\n        if pms.bds.bds44.is44(msg):\n            data[\"Wind speed (kt) and direction (true) (deg)\"] = pms.commb.wind44(msg)\n            sat = pms.commb.temp44(msg)\n            data[\"Static air temperature (C)\"] = processStaticAirTemperature(sat)\n            data[\"Average static pressure (hPa)\"] = pms.commb.p44(msg)\n            data[\"Humidity (%)\"] = pms.commb.hum44(msg)\n        \n        # BDS 4,5\n        if pms.bds.bds45.is45(msg):\n            data[\"Turbulence level (0-3)\"] = pms.commb.turb45(msg)\n            data[\"Wind shear level (0-3)\"] = pms.commb.ws45(msg)\n            data[\"Microburst level (0-3)\"] = pms.commb.mb45(msg)\n            data[\"Icing level (0-3)\"] = pms.commb.ic45(msg)\n            data[\"Wake vortex level (0-3)\"] = pms.commb.wv45(msg)\n            sat = pms.commb.temp45(msg)\n            data[\"Static air temperature (C)\"] = processStaticAirTemperature(sat)\n            data[\"Average static pressure (hPa)\"] = pms.commb.p45(msg)\n            data[\"Radio height (ft)\"] = pms.commb.rh45(msg)\n\n        # BDS 5,0\n        if pms.bds.bds50.is50(msg):\n            data[\"Roll angle (deg)\"] = pms.commb.roll50(msg)\n            data[\"True track angle (deg)\"] = pms.commb.trk50(msg)\n            data[\"Ground speed (kt)\"] = pms.commb.gs50(msg)\n            data[\"Track angle rate (deg/sec)\"] = pms.commb.rtrk50(msg)\n            data[\"True airspeed (kt)\"] = pms.commb.tas50(msg)\n\n        # BDS 6,0\n        if pms.bds.bds60.is60(msg):\n            data[\"Magnetic heading (deg)\"] = pms.commb.hdg60(msg)\n            data[\"Indicated airspeed (kt)\"] = pms.commb.ias60(msg)\n            data[\"Mach number (-)\"] = pms.commb.mach60(msg)\n            data[\"Barometric altitude rate (ft/min)\"] = pms.commb.vr60baro(msg)   \n            data[\"Inertial vertical speed (ft/min)\"] = pms.commb.vr60ins(msg)\n        \n        return data\n","user":"jmarti32","dateUpdated":"2025-04-16T14:46:14+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1744814774144_269919","id":"20250416-135728_2022777984","dateCreated":"2025-04-16T14:46:14+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:172"},{"text":"%livy3.pyspark\nfrom pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType, TimestampType\n\n# Esquema actualizado basado en el Decoder y las funciones adicionales\nschema = StructType([\n    StructField(\"Timestamp (kafka)\", IntegerType(), True),\n    StructField(\"Timestamp (date)\", TimestampType(), True),\n    StructField(\"Message (base64)\", StringType(), True),\n    StructField(\"Message (hex)\", StringType(), True),\n    StructField(\"ICAO\", StringType(), True),\n    StructField(\"Downlink Format\", IntegerType(), True),\n    StructField(\"Flight status\", StringType(), True),\n    StructField(\"Altitude (ft)\", FloatType(), True),\n    StructField(\"Squawk code\", StringType(), True),\n    StructField(\"Typecode\", IntegerType(), True),\n    StructField(\"TurbulenceCategory\", StringType(), True),\n    StructField(\"Callsign\", StringType(), True),\n    StructField(\"Speed heading\", StringType(), True),\n    StructField(\"Position with ref (RADAR)\", StringType(), True),\n    StructField(\"BDS\", StringType(), True),\n    StructField(\"Overlay capability\", StringType(), True),\n    StructField(\"GICB capability\", StringType(), True),\n    StructField(\"MCP/FCU selected altitude (ft)\", FloatType(), True),\n    StructField(\"FMS selected altitude (ft)\", FloatType(), True),\n    StructField(\"Barometric pressure (mb)\", FloatType(), True),\n    StructField(\"Wind speed (kt) and direction (true) (deg)\", StringType(), True),\n    StructField(\"Static air temperature (C)\", FloatType(), True),\n    StructField(\"Average static pressure (hPa)\", FloatType(), True),\n    StructField(\"Humidity (%)\", FloatType(), True),\n    StructField(\"Turbulence level (0-3)\", IntegerType(), True),\n    StructField(\"Wind shear level (0-3)\", IntegerType(), True),\n    StructField(\"Microburst level (0-3)\", IntegerType(), True),\n    StructField(\"Icing level (0-3)\", IntegerType(), True),\n    StructField(\"Wake vortex level (0-3)\", IntegerType(), True),\n    StructField(\"Radio height (ft)\", FloatType(), True),\n    StructField(\"Roll angle (deg)\", FloatType(), True),\n    StructField(\"True track angle (deg)\", FloatType(), True),\n    StructField(\"Ground speed (kt)\", FloatType(), True),\n    StructField(\"Track angle rate (deg/sec)\", FloatType(), True),\n    StructField(\"True airspeed (kt)\", FloatType(), True),\n    StructField(\"Magnetic heading (deg)\", FloatType(), True),\n    StructField(\"Indicated airspeed (kt)\", FloatType(), True),\n    StructField(\"Mach number (-)\", FloatType(), True),\n    StructField(\"Barometric altitude rate (ft/min)\", FloatType(), True),\n    StructField(\"Inertial vertical speed (ft/min)\", FloatType(), True),\n    # Columnas adicionales generadas por separateCoordinates:\n    StructField(\"lat\", FloatType(), True),\n    StructField(\"lon\", FloatType(), True),\n    # Columnas adicionales generadas por separateVelocity:\n    StructField(\"Speed\", FloatType(), True),\n    StructField(\"Angle\", FloatType(), True),\n    StructField(\"Vertical rate\", FloatType(), True),\n    StructField(\"Speed type\", FloatType(), True),\n])\n\ndecoded_keys = [field.name for field in schema.fields]\n","user":"jmarti32","dateUpdated":"2025-04-16T14:46:14+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1744814774144_-1551164133","id":"20250416-135745_1149863621","dateCreated":"2025-04-16T14:46:14+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:173"},{"text":"%livy3.pyspark\nfrom pyspark.sql.functions import col, when, udf\nfrom pyspark.sql.types import MapType, StringType, StructType, StructField, Row\nfrom datetime import datetime, timedelta\n\n\n@udf(returnType=MapType(StringType(), StringType()))\ndef decode_message(message, ts_kafka):\n    try:\n        result = Decoder.processMessage(message, ts_kafka)\n        return {str(k): str(v) for k, v in result.items()}\n    except:\n        return {}\n\ndef dict_to_row(d):\n    return Row(**{k: d.get(k, None) for k in decoded_keys})\n\ndef read_raw_csv(spark, path):\n    return spark.read.option(\"header\", \"true\").option(\"sep\", \";\").csv(path)\n\ndef decode_and_structure(df_raw):\n    df_decoded = df_raw.withColumn(\"decoded\", decode_message(\"message\", \"ts_kafka\"))\n    rows_rdd = df_decoded.select(\"decoded\").rdd.map(lambda x: dict_to_row(x[\"decoded\"]))\n    \n    columnas = rows_rdd.first().asDict().keys()\n    schema_str = StructType([StructField(col_name, StringType(), True) for col_name in columnas])\n    \n    return spark.createDataFrame(rows_rdd, schema=schema_str)\n\ndef clean_and_cast(df):\n    for c in df.columns:\n        df = df.withColumn(c, when(col(c).isNull(), \"NaN\").otherwise(col(c)))\n    df = df.replace(\"None\", \"NaN\").na.fill(\"NaN\")\n\n    # Aquí aplica el casteo de tipos como ya hiciste (pegamos directamente):\n    df = df \\\n        .withColumn(\"Timestamp (date)\", col(\"Timestamp (date)\").cast(\"timestamp\")) \\\n        .withColumn(\"Timestamp (kafka)\", col(\"Timestamp (kafka)\").cast(\"integer\")) \\\n        .withColumn(\"Downlink Format\", col(\"Downlink Format\").cast(\"integer\")) \\\n        .withColumn(\"Altitude (ft)\", col(\"Altitude (ft)\").cast(\"float\")) \\\n        .withColumn(\"Typecode\", col(\"Typecode\").cast(\"integer\")) \\\n        .withColumn(\"TurbulenceCategory\", col(\"TurbulenceCategory\").cast(\"string\")) \\\n        .withColumn(\"Flight status\", col(\"Flight status\").cast(\"string\")) \\\n        .withColumn(\"Speed heading\", col(\"Speed heading\").cast(\"string\")) \\\n        .withColumn(\"BDS\", col(\"BDS\").cast(\"string\")) \\\n        .withColumn(\"Overlay capability\", col(\"Overlay capability\").cast(\"string\")) \\\n        .withColumn(\"GICB capability\", col(\"GICB capability\").cast(\"string\")) \\\n        .withColumn(\"MCP/FCU selected altitude (ft)\", col(\"MCP/FCU selected altitude (ft)\").cast(\"float\")) \\\n        .withColumn(\"FMS selected altitude (ft)\", col(\"FMS selected altitude (ft)\").cast(\"float\")) \\\n        .withColumn(\"Barometric pressure (mb)\", col(\"Barometric pressure (mb)\").cast(\"float\")) \\\n        .withColumn(\"Static air temperature (C)\", col(\"Static air temperature (C)\").cast(\"float\")) \\\n        .withColumn(\"Average static pressure (hPa)\", col(\"Average static pressure (hPa)\").cast(\"float\")) \\\n        .withColumn(\"Humidity (%)\", col(\"Humidity (%)\").cast(\"float\")) \\\n        .withColumn(\"Turbulence level (0-3)\", col(\"Turbulence level (0-3)\").cast(\"integer\")) \\\n        .withColumn(\"Wind shear level (0-3)\", col(\"Wind shear level (0-3)\").cast(\"integer\")) \\\n        .withColumn(\"Microburst level (0-3)\", col(\"Microburst level (0-3)\").cast(\"integer\")) \\\n        .withColumn(\"Icing level (0-3)\", col(\"Icing level (0-3)\").cast(\"integer\")) \\\n        .withColumn(\"Wake vortex level (0-3)\", col(\"Wake vortex level (0-3)\").cast(\"integer\")) \\\n        .withColumn(\"Radio height (ft)\", col(\"Radio height (ft)\").cast(\"float\")) \\\n        .withColumn(\"Roll angle (deg)\", col(\"Roll angle (deg)\").cast(\"float\")) \\\n        .withColumn(\"True track angle (deg)\", col(\"True track angle (deg)\").cast(\"float\")) \\\n        .withColumn(\"Ground speed (kt)\", col(\"Ground speed (kt)\").cast(\"float\")) \\\n        .withColumn(\"Track angle rate (deg/sec)\", col(\"Track angle rate (deg/sec)\").cast(\"float\")) \\\n        .withColumn(\"True airspeed (kt)\", col(\"True airspeed (kt)\").cast(\"float\")) \\\n        .withColumn(\"Magnetic heading (deg)\", col(\"Magnetic heading (deg)\").cast(\"float\")) \\\n        .withColumn(\"Indicated airspeed (kt)\", col(\"Indicated airspeed (kt)\").cast(\"float\")) \\\n        .withColumn(\"Mach number (-)\", col(\"Mach number (-)\").cast(\"float\")) \\\n        .withColumn(\"Barometric altitude rate (ft/min)\", col(\"Barometric altitude rate (ft/min)\").cast(\"float\")) \\\n        .withColumn(\"Inertial vertical speed (ft/min)\", col(\"Inertial vertical speed (ft/min)\").cast(\"float\")) \\\n        .withColumn(\"lat\", col(\"lat\").cast(\"float\")) \\\n        .withColumn(\"lon\", col(\"lon\").cast(\"float\")) \\\n        .withColumn(\"Speed\", col(\"Speed\").cast(\"float\")) \\\n        .withColumn(\"Angle\", col(\"Angle\").cast(\"float\")) \\\n        .withColumn(\"Vertical rate\", col(\"Vertical rate\").cast(\"float\")) \\\n        .withColumn(\"Speed type\", col(\"Speed type\").cast(\"float\"))\n\n    return df\n\ndef save_as_parquet(df, path):\n    df.repartition(10).write.option(\"dfs.replication\", 1).mode(\"overwrite\").parquet(path)\n\ndef run_pipeline_for_date(spark, date):\n    ruta_csv = f\"/data/aviones/2024/11/{date.day:02d}/*/*.csv\"\n    output_path = f\"/data/proyecto2/outputs/iberIA/decoded/dia_{date.day:02d}_11_2024.parquet\"\n    \n    print(f\"Procesando día: {date.strftime('%d/%m/%Y')}\")\n    \n    df_raw = read_raw_csv(spark, ruta_csv)\n    df_structured = decode_and_structure(df_raw)\n    df_cleaned = clean_and_cast(df_structured)\n    save_as_parquet(df_cleaned, output_path)\n    \n    print(f\"Guardado en: {output_path}\")\n\ndef run_pipeline_range(spark, start_date, end_date):\n    current = start_date\n    while current <= end_date:\n        run_pipeline_for_date(spark, current)\n        current += timedelta(days=1)\n","user":"jmarti32","dateUpdated":"2025-04-16T14:46:14+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1744814774144_-2029426353","id":"20250416-135804_73485924","dateCreated":"2025-04-16T14:46:14+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:174"},{"text":"%livy3.pyspark\nfrom datetime import datetime\n\nstart = datetime(2024, 11, 14)\nend = datetime(2024, 11, 22)\n\nrun_pipeline_range(spark, start, end)\n","user":"jmarti32","dateUpdated":"2025-04-16T14:46:14+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1744814774145_-492871537","id":"20250416-135857_115088098","dateCreated":"2025-04-16T14:46:14+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:175"}],"name":"PipelineDecoder","id":"2KSBYAXPD","noteParams":{},"noteForms":{},"angularObjects":{"livy3:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}