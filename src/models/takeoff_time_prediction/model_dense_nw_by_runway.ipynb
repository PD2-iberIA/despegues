{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a38e49ff-48e2-4d22-8232-add20dc4cd8c",
   "metadata": {},
   "source": [
    "# MODELADO\n",
    "\n",
    "## Dense Newtork\n",
    "\n",
    "\n",
    "<hr>\n",
    "\n",
    "<code> **Proyecto de Datos II** </code>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7c845b-dd88-42f7-aba6-1e2778fa821a",
   "metadata": {},
   "source": [
    "## Índice\n",
    "\n",
    "- [Importación de los datos](#importación-de-los-datos)\n",
    "- [Preprocesamiento](#preprocesamiento)\n",
    "- [Entrenamiento](#entrenamiento)\n",
    "- [Análisis del modelo](#análisis-del-modelo)\n",
    "- [Registro del modelo en MLflow](#registro-del-modelo-en-mlflow)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2f464da-fc1a-45ba-a080-6cfde2316aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "from evaluation.evaluator import Evaluator\n",
    "\n",
    "SEED = 22 # replicabilidad\n",
    "\n",
    "# =====================================\n",
    "MODEL_NAME = \"dense_network_by_runway\"\n",
    "# ====================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd637b55-3e74-410d-819b-6aa19ed9c30e",
   "metadata": {},
   "source": [
    "## Importación de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38ba53f-1529-4579-9a4d-544f43a44c7e",
   "metadata": {},
   "source": [
    "Se ha tomado del conjunto de datos de entrenamiento como validación del 1 al 14 de enero (los mensajes más recientes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aeffee5d-bee7-47cb-ad3a-da90737097b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "import keras_tuner as kt\n",
    "\n",
    "# Cargamos los datos\n",
    "df_train = pd.read_parquet(\"../data/train.parquet\")\n",
    "df_test = pd.read_parquet(\"../data/test.parquet\")\n",
    "\n",
    "# Separamos en variable objetivo y features\n",
    "X_train_full = df_train.drop(columns=\"takeoff_time\")\n",
    "y_train_full = df_train[\"takeoff_time\"]\n",
    "\n",
    "X_test = df_test.drop(columns=\"takeoff_time\")\n",
    "y_test = df_test[\"takeoff_time\"]\n",
    "\n",
    "# Convertimos columna timestamp a datetime\n",
    "X_train_full[\"timestamp\"] = pd.to_datetime(X_train_full[\"timestamp\"])\n",
    "\n",
    "# Dividimos entre train y validation basado en fecha para evitar contaminación de futuro\n",
    "split_date = pd.to_datetime(\"2025-01-01\")\n",
    "train_mask = X_train_full[\"timestamp\"] < split_date\n",
    "val_mask = X_train_full[\"timestamp\"] >= split_date\n",
    "\n",
    "X_train = X_train_full[train_mask].drop(columns=[\"timestamp\", \"icao\", \"callsign\"])\n",
    "y_train = y_train_full[train_mask]\n",
    "\n",
    "X_val = X_train_full[val_mask].drop(columns=[\"timestamp\", \"icao\", \"callsign\"])\n",
    "y_val = y_train_full[val_mask]\n",
    "\n",
    "X_test = X_test.drop(columns=[\"timestamp\", \"icao\", \"callsign\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ea6d533-6fcb-4a43-93f9-0fccd38e6198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((98645, 57), (25088, 57), (27791, 57))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a847e73-4ee8-4336-9efb-d74bcbc788c9",
   "metadata": {},
   "source": [
    "## Preprocesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f48508-7b36-4716-a46f-00737a730c94",
   "metadata": {},
   "source": [
    "Asimismo, también le hemos realizado una transformación logarítmica a la variable respuesta, lo cual mejora ligeramente los resultados del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c64cfcc3-9d57-4491-997f-f33a70228e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding\n",
    "X_train_c = X_train\n",
    "X_val_c = X_val\n",
    "X_test_c = X_test\n",
    "\n",
    "X_train = pd.get_dummies(X_train, drop_first=True)\n",
    "X_val = pd.get_dummies(X_val, drop_first=True)\n",
    "X_test = pd.get_dummies(X_test, drop_first=True)\n",
    "\n",
    "# Alineamos columnas por si falta alguna categoría\n",
    "X_val = X_val.reindex(columns=X_train.columns, fill_value=0)\n",
    "X_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "# Escalamos las variables numéricas\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25078f0-34aa-4eca-acac-646f3b819823",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98e6f69a-b80b-45e9-8629-790298d53b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20 Complete [00h 00m 20s]\n",
      "val_mae: 126.67001342773438\n",
      "\n",
      "Best val_mae So Far: 120.95462036132812\n",
      "Total elapsed time: 00h 04m 50s\n",
      "\n",
      "Entrenando modelo final para runway = 32L/14R con mejores hiperparámetros...\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/optimizers/base_optimizer.py:86: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 - 1s - 20ms/step - loss: 31050.8711 - mae: 129.4714 - val_loss: 37389.9766 - val_mae: 146.3074\n",
      "Epoch 2/100\n",
      "58/58 - 1s - 13ms/step - loss: 6383.1870 - mae: 59.6084 - val_loss: 36131.6875 - val_mae: 140.4044\n",
      "Epoch 3/100\n",
      "58/58 - 1s - 13ms/step - loss: 3945.2896 - mae: 46.3159 - val_loss: 34379.0039 - val_mae: 131.9752\n",
      "Epoch 4/100\n",
      "58/58 - 1s - 13ms/step - loss: 2496.0610 - mae: 36.9849 - val_loss: 33522.8789 - val_mae: 126.5166\n",
      "Epoch 5/100\n",
      "58/58 - 1s - 13ms/step - loss: 1717.6821 - mae: 30.2045 - val_loss: 33463.8477 - val_mae: 122.9222\n",
      "Epoch 6/100\n",
      "58/58 - 1s - 13ms/step - loss: 1278.5308 - mae: 25.8570 - val_loss: 34088.0156 - val_mae: 121.5498\n",
      "Epoch 7/100\n",
      "58/58 - 1s - 13ms/step - loss: 1039.0775 - mae: 23.3517 - val_loss: 35040.4023 - val_mae: 121.9139\n",
      "Epoch 8/100\n",
      "58/58 - 1s - 13ms/step - loss: 851.7244 - mae: 21.1158 - val_loss: 35782.4141 - val_mae: 122.1730\n",
      "Epoch 9/100\n",
      "58/58 - 1s - 13ms/step - loss: 856.1193 - mae: 21.1830 - val_loss: 36214.1836 - val_mae: 122.2297\n",
      "Epoch 10/100\n",
      "58/58 - 1s - 13ms/step - loss: 806.9404 - mae: 21.0073 - val_loss: 37157.4062 - val_mae: 122.5705\n",
      "Epoch 11/100\n",
      "58/58 - 1s - 13ms/step - loss: 716.6413 - mae: 19.6181 - val_loss: 37737.1289 - val_mae: 123.2185\n",
      "Test MAE para runway 32L/14R: 107.80\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "import keras_tuner as kt\n",
    "import time\n",
    "\n",
    "# Registramos el tiempo de inicio para calcular el tiempo total de ejecución\n",
    "start_time = time.time()\n",
    "\n",
    "# Definimos la función de construcción del modelo para usar con Keras Tuner\n",
    "def build_model(hp, input_shape):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Input(shape=(input_shape,)))\n",
    "\n",
    "    # Elegimos aleatoriamente entre 1 y 3 capas ocultas\n",
    "    num_layers = hp.Int('num_layers', 1, 3)\n",
    "    for i in range(num_layers):\n",
    "        # Añadimos una capa densa con un número de unidades entre 64 y 512\n",
    "        model.add(layers.Dense(\n",
    "            units=hp.Int(f'units_{i}', min_value=64, max_value=512, step=64),\n",
    "            activation='relu'\n",
    "        ))\n",
    "\n",
    "        # Añadimos una capa Dropout para reducir el riesgo de sobreajuste\n",
    "        model.add(layers.Dropout(rate=hp.Float(f'dropout_{i}', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "\n",
    "    # Capa de salida para regresión\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    # Compilamos el modelo con el optimizador Adam, explorando valores para el learning rate y su decaimiento\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(\n",
    "            learning_rate=hp.Float('learning_rate', 1e-5, 1e-2, sampling='LOG'),\n",
    "            decay=hp.Float('lr_decay', 1e-6, 1e-3, sampling='LOG')\n",
    "        ),\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Definimos la función que se encargará de ejecutar la optimización de hiperparámetros\n",
    "def tune_model(X_train_scaled, y_train, X_val_scaled, y_val):\n",
    "    tuner = kt.BayesianOptimization(\n",
    "        lambda hp: build_model(hp, X_train_scaled.shape[1]),\n",
    "        objective='val_mae',\n",
    "        max_trials=20,\n",
    "        directory='kt_tuning_dir_bayesian',\n",
    "        project_name='takeoff_time',\n",
    "        overwrite=True\n",
    "    )\n",
    "\n",
    "    # Usamos EarlyStopping para evitar sobreentrenamiento durante el tuning\n",
    "    early_stop = callbacks.EarlyStopping(monitor='val_mae', patience=5, restore_best_weights=True)\n",
    "\n",
    "    # Ejecutamos la búsqueda de hiperparámetros\n",
    "    tuner.search(\n",
    "        X_train_scaled, y_train,\n",
    "        validation_data=(X_val_scaled, y_val),\n",
    "        epochs=30,\n",
    "        batch_size=32,\n",
    "        callbacks=[early_stop],\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    # Obtenemos los mejores hiperparámetros encontrados\n",
    "    best_hp = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "    return best_hp, tuner\n",
    "\n",
    "# Entrenamos modelos individuales para cada valor único de pista (runway)\n",
    "def train_models_per_runway(X_train_scaled, X_val_scaled, X_test_scaled, y_train, y_val, y_test):\n",
    "    model_results = {}\n",
    "\n",
    "    for runway_value in df_train['runway'].unique():\n",
    "        print(f\"\\nEntrenando modelo para runway = {runway_value}\")\n",
    "        \n",
    "        # Filtramos las observaciones que corresponden a la pista actual\n",
    "        train_indices = X_train_c[\"runway\"] == runway_value\n",
    "        val_indices = X_val_c[\"runway\"] == runway_value\n",
    "        test_indices = X_test_c[\"runway\"] == runway_value\n",
    "\n",
    "        X_train_runway = X_train_scaled[train_indices]\n",
    "        y_train_runway = y_train[train_indices]\n",
    "\n",
    "        X_val_runway = X_val_scaled[val_indices]\n",
    "        y_val_runway = y_val[val_indices]\n",
    "\n",
    "        X_test_runway = X_test_scaled[test_indices]\n",
    "        y_test_runway = y_test[test_indices]\n",
    "\n",
    "        # Ejecutamos el tuning de hiperparámetros para la pista actual\n",
    "        print(\"\\nBuscando mejores hiperparámetros...\")\n",
    "        best_hp, tuner = tune_model(X_train_runway, y_train_runway, X_val_scaled, y_val)\n",
    "\n",
    "        # Entrenamos el modelo final usando los mejores hiperparámetros\n",
    "        print(f\"\\nEntrenando modelo final para runway = {runway_value} con mejores hiperparámetros...\")\n",
    "        final_model = build_model(best_hp, X_train_runway.shape[1])\n",
    "\n",
    "        early_stop_final = callbacks.EarlyStopping(monitor='val_mae', patience=5, restore_best_weights=True)\n",
    "\n",
    "        history = final_model.fit(\n",
    "            X_train_runway, y_train_runway,\n",
    "            validation_data=(X_val_scaled, y_val),\n",
    "            epochs=100,\n",
    "            batch_size=32,\n",
    "            callbacks=[early_stop_final],\n",
    "            verbose=2\n",
    "        )\n",
    "\n",
    "        # Evaluamos el modelo sobre el conjunto de prueba\n",
    "        test_loss, test_mae = final_model.evaluate(X_test_runway, y_test_runway, verbose=0)\n",
    "        print(f\"Test MAE para runway {runway_value}: {test_mae:.2f}\")\n",
    "\n",
    "        # Almacenamos los resultados de cada modelo en un diccionario\n",
    "        model_results[runway_value] = {\n",
    "            'model': final_model,\n",
    "            'mae': test_mae,\n",
    "            'history': history.history,\n",
    "        }\n",
    "\n",
    "    return model_results\n",
    "\n",
    "# Llamamos a la función para entrenar un modelo por cada pista\n",
    "model_results = train_models_per_runway(X_train_scaled, X_val_scaled, X_test_scaled, y_train, y_val, y_test)\n",
    "\n",
    "# Calculamos el tiempo total de ejecución del proceso\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7d7c37-0f01-4224-8fcf-9425f2be2481",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7970bbdb-c953-4e17-8bb8-c99b1187dd03",
   "metadata": {},
   "source": [
    "## Análisis del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6cd1f60-b05f-4ef2-b806-15ac8b31e0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3083/3083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 449us/step\n",
      "\u001b[1m784/784\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441us/step\n",
      "\u001b[1m3083/3083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 339us/step\n",
      "\u001b[1m784/784\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343us/step\n",
      "\u001b[1m3083/3083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 662us/step\n",
      "\u001b[1m784/784\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 700us/step\n",
      "\u001b[1m3083/3083\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 602us/step\n",
      "\u001b[1m784/784\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 725us/step\n",
      "MAE promedio en entrenamiento: 87.3972\n",
      "RMSE promedio en entrenamiento: 130.6235\n",
      "MAE promedio en validación: 105.8320\n",
      "RMSE promedio en validación: 162.9917\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Inicializamos listas para almacenar los MAE y RMSE de cada modelo\n",
    "mae_train_list = []\n",
    "rmse_train_list = []\n",
    "\n",
    "mae_val_list = []\n",
    "rmse_val_list = []\n",
    "\n",
    "# Recorremos los resultados de cada runway\n",
    "for runway_value, result in model_results.items():\n",
    "    model = result['model']\n",
    "    \n",
    "    # Predicciones en el conjunto de entrenamiento\n",
    "    y_train_pred = model.predict(X_train_scaled)  # Predicciones sobre X_train_scaled\n",
    "    mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "    rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "    \n",
    "    # Predicciones en el conjunto de validación\n",
    "    y_val_pred = model.predict(X_val_scaled)  # Predicciones sobre X_val_scaled\n",
    "    mae_val = mean_absolute_error(y_val, y_val_pred)\n",
    "    rmse_val = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "    \n",
    "    # Almacenamos los valores\n",
    "    mae_train_list.append(mae_train)\n",
    "    rmse_train_list.append(rmse_train)\n",
    "    \n",
    "    mae_val_list.append(mae_val)\n",
    "    rmse_val_list.append(rmse_val)\n",
    "\n",
    "# Calculamos la media de los MAE y RMSE en entrenamiento y validación\n",
    "mae_train= np.mean(mae_train_list)\n",
    "rmse_train = np.mean(rmse_train_list)\n",
    "\n",
    "mae_val = np.mean(mae_val_list)\n",
    "rmse_val = np.mean(rmse_val_list)\n",
    "\n",
    "# Mostramos los resultados\n",
    "print(f\"MAE promedio en entrenamiento: {mae_train:.4f}\")\n",
    "print(f\"RMSE promedio en entrenamiento: {rmse_train:.4f}\")\n",
    "print(f\"MAE promedio en validación: {mae_val:.4f}\")\n",
    "print(f\"RMSE promedio en validación: {rmse_val:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1469d262-f7d3-4167-9291-07bb4b685fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m315/315\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step\n",
      "\u001b[1m268/268\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 775us/step\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step\n"
     ]
    }
   ],
   "source": [
    "# Inicializar una columna de predicciones en df_test\n",
    "df_test['prediction'] = np.nan\n",
    "\n",
    "# Iteramos sobre cada modelo y su correspondiente pista\n",
    "for runway_value, result in model_results.items():\n",
    "    model = result['model']\n",
    "    runway_data = df_test[df_test['runway'] == runway_value].copy()  # Filtramos datos por runway\n",
    "\n",
    "    if runway_data.empty:\n",
    "        continue\n",
    "\n",
    "    test_indices = X_test_c[\"runway\"] == runway_value\n",
    "\n",
    "    X_test_runway = X_test_scaled[test_indices]\n",
    "    y_test_runway = y_test[test_indices]\n",
    "\n",
    "    # Hacemos las predicciones usando el modelo correspondiente\n",
    "    y_runway_pred = model.predict(X_test_runway)\n",
    "\n",
    "    # Asignamos las predicciones al df original de test\n",
    "    df_test.loc[df_test['runway'] == runway_value, 'prediction'] = y_runway_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18706da7-ae3b-4003-8bcb-6dc73a0194ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x13b8740b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Nota: df_test tiene que tener la columna 'prediction'\n",
    "ev = Evaluator(df_test, MODEL_NAME, mae_val, rmse_val)\n",
    "report = ev.getReport()\n",
    "ev.visualEvaluation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc79d07-4d85-4dba-8242-331e8102d0ca",
   "metadata": {},
   "source": [
    "## Registro del modelo en MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4654dd7-3e73-41b8-b7f8-eeb559fff34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/27 00:46:41 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "\u001b[31m2025/04/27 00:46:51 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025/04/27 00:46:51 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "\u001b[31m2025/04/27 00:46:57 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025/04/27 00:46:57 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "\u001b[31m2025/04/27 00:47:02 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025/04/27 00:47:02 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "\u001b[31m2025/04/27 00:47:07 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"file:./mlflow_experiments\")\n",
    "mlflow.set_experiment(\"takeoff_time_prediction\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "\n",
    "    # - Datos generales -\n",
    "\n",
    "    # ========================================================================\n",
    "    mlflow.set_tag(\"model_type\", MODEL_NAME)\n",
    "    mlflow.set_tag(\"framework\", \"tensorflow\") # scikit-learn, tensorflow, etc.\n",
    "    mlflow.set_tag(\"target_variable\", \"takeoff_time\") # variable respuesta\n",
    "    mlflow.set_tag(\"preprocessing\", \"standard scaler\") # transformaciones separadas por un +\n",
    "    mlflow.set_tag(\"dataset\", \"original\") # indicar si se ha modificado el conjunto de datos\n",
    "    mlflow.set_tag(\"seed\", SEED) # semilla para replicabilidad\n",
    "    # ========================================================================\n",
    "    \n",
    "\n",
    "    # - Métricas -\n",
    "\n",
    "    mlflow.log_metric(\"execution_time_s\", execution_time)\n",
    "\n",
    "    mlflow.log_metric(\"mae_val\", mae_val)\n",
    "    mlflow.log_metric(\"rmse_val\", rmse_val)\n",
    "\n",
    "    mlflow.log_metric(\"mae_train\", mae_train)\n",
    "    mlflow.log_metric(\"rmse_train\", rmse_train)\n",
    "\n",
    "    # Registrar métricas globales en test\n",
    "    for metric_name, value in report[\"global\"].items():\n",
    "        mlflow.log_metric(f\"{metric_name}_test\", value)\n",
    "    \n",
    "    # Registrar métricas por runway\n",
    "    for runway, metrics in report[\"by_runway\"].items():\n",
    "        for metric_name, value in metrics.items():\n",
    "            mlflow.log_metric(f\"{metric_name}_test_runway_{runway}\", value)\n",
    "    \n",
    "    # Registrar métricas por holding point\n",
    "    for hp, metrics in report[\"by_holding_point\"].items():\n",
    "        for metric_name, value in metrics.items():\n",
    "            mlflow.log_metric(f\"{metric_name}_test_hp_{hp}\", value)\n",
    "\n",
    "    for runway_value, result in model_results.items():\n",
    "        model = result['model']\n",
    "    \n",
    "        # Guardar los hiperparámetros de este modelo\n",
    "        if 'best_hp' in locals():\n",
    "            best_hp_dict_runway = {key: value for key, value in best_hp.items()}  # Convertir a un diccionario\n",
    "            # Agregar el runway_value al nombre de los parámetros\n",
    "            mlflow.log_params({f\"{key}_runway_{runway_value}\": value for key, value in best_hp_dict_runway.items()})\n",
    "        \n",
    "        # Guardar el modelo de cada runway\n",
    "        mlflow.keras.log_model(model, f\"model_runway_{runway_value}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0aa475d6-3fd2-41c8-9916-5ce17302c8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Visualizar experimentos -\n",
    "# !mlflow ui --backend-store-uri ./mlflow_experiments"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
