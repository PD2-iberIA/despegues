{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a38e49ff-48e2-4d22-8232-add20dc4cd8c",
   "metadata": {},
   "source": [
    "# MODELADO\n",
    "\n",
    "## HEURÍSTICA II\n",
    "\n",
    "\n",
    "<hr>\n",
    "\n",
    "<code> **Proyecto de Datos II** </code>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7c845b-dd88-42f7-aba6-1e2778fa821a",
   "metadata": {},
   "source": [
    "## Índice\n",
    "\n",
    "- [Importación de los datos](#importación-de-los-datos)\n",
    "- [Preprocesamiento](#preprocesamiento)\n",
    "- [Entrenamiento](#entrenamiento)\n",
    "- [Análisis del modelo](#análisis-del-modelo)\n",
    "- [Registro del modelo en MLflow](#registro-del-modelo-en-mlflow)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2f464da-fc1a-45ba-a080-6cfde2316aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "from evaluation.evaluator import Evaluator\n",
    "\n",
    "SEED = 22 # replicabilidad\n",
    "\n",
    "# =====================================\n",
    "MODEL_NAME = \"Heurística II\"\n",
    "# ====================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd637b55-3e74-410d-819b-6aa19ed9c30e",
   "metadata": {},
   "source": [
    "## Importación de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aeffee5d-bee7-47cb-ad3a-da90737097b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_parquet(\"../data/train.parquet\")\n",
    "df_test = pd.read_parquet(\"../data/test.parquet\")\n",
    "\n",
    "# ! NOTA -> están el ICAO, Callsign y Timestamp por si hay que depurar\n",
    "X_train, y_train = df_train.drop(columns=\"takeoff_time\", axis=1), df_train[\"takeoff_time\"]\n",
    "X_test, y_test = df_test.drop(columns=\"takeoff_time\", axis=1), df_test[\"takeoff_time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ea6d533-6fcb-4a43-93f9-0fccd38e6198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((123733, 60), (27791, 60))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a847e73-4ee8-4336-9efb-d74bcbc788c9",
   "metadata": {},
   "source": [
    "## Preprocesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3616bd4e-c0ed-4cb8-a7e0-a7196e2a750a",
   "metadata": {},
   "source": [
    "Para la heurística definida no será necesario ningún tipo de preprocesamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25078f0-34aa-4eca-acac-646f3b819823",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e057a5d8-17f0-49e6-8343-cc4ccc1296a3",
   "metadata": {},
   "source": [
    "Esta segunda heurística se define como:\n",
    "\n",
    "    «Un avión esperará el promedio de los últimos tres tiempos de espera de las aeronaves en su misma pista».\n",
    "\n",
    "A la hora de calcular las predicciones es importante coger aviones con cuyo tiempo de espera no se exceda el timestamp del avión que nos interesa, puesto que estaríamos empleando información futura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a1abd7f-5b67-4899-8739-6dfd8642f458",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def h(df):\n",
    "    df['date'] = df['timestamp'].dt.date\n",
    "    df = df.sort_values(by='timestamp')\n",
    "\n",
    "    # 3. Inicializar lista para las predicciones\n",
    "    predictions = []\n",
    "\n",
    "    # 4. Aplicar predicción a todo el DataFrame\n",
    "    for idx, row in df.iterrows():\n",
    "        # Filtrar los eventos anteriores en la misma pista, el mismo día y con callsign distinto\n",
    "        mask = (\n",
    "            (df['runway'] == row['runway']) & \n",
    "            (df['date'] == row['date']) & \n",
    "            (df['timestamp'] < row['timestamp']) & \n",
    "            (df['callsign'] != row['callsign']) & \n",
    "            (pd.to_timedelta(df['takeoff_time'], unit='s') + df['timestamp'] < row['timestamp'])\n",
    "        )\n",
    "        \n",
    "        previous_events = df[mask]\n",
    "        \n",
    "        # Agrupar por callsign y tomar el mensaje más antiguo (primero) de cada avión\n",
    "        grouped_events = previous_events.groupby('callsign').first().reset_index()\n",
    "\n",
    "        # Tomar los 3 eventos más recientes de los aviones válidos\n",
    "        recent_events = grouped_events.sort_values(by='timestamp', ascending=False).head(3)\n",
    "        \n",
    "        if not recent_events.empty:\n",
    "            pred = recent_events['takeoff_time'].mean()  # Promedio de los 3 anteriores\n",
    "        else:\n",
    "            pred = 170  # Valor por defecto cuando no hay eventos válidos\n",
    "        \n",
    "        predictions.append(pred)\n",
    "\n",
    "    # 5. Asignar las predicciones a la columna 'prediction' en el DataFrame\n",
    "    df['prediction'] = predictions\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98e6f69a-b80b-45e9-8629-790298d53b5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "df_train = h(df_train)\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c462fe8e-68bd-44ff-87ec-bdd69167d489",
   "metadata": {},
   "source": [
    "**Observación** - Las operaciones de agregación hacen que sea una heurística significativamente lenta.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7970bbdb-c953-4e17-8bb8-c99b1187dd03",
   "metadata": {},
   "source": [
    "## Análisis del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8208569-0e8c-436b-9a37-2c633289686b",
   "metadata": {},
   "source": [
    "Realizamos las predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6cd1f60-b05f-4ef2-b806-15ac8b31e0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# ===============================================================\n",
    "y_true = df_train['takeoff_time']\n",
    "y_pred = df_train['prediction']\n",
    "\n",
    "mae_train = mean_absolute_error(y_true, y_pred)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "mae_val = None\n",
    "rmse_val = None\n",
    "# ==============================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1469d262-f7d3-4167-9291-07bb4b685fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = h(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18706da7-ae3b-4003-8bcb-6dc73a0194ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x143da3da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Nota: df_test tiene que tener la columna 'prediction'\n",
    "ev = Evaluator(df_test, MODEL_NAME)\n",
    "report = ev.getReport()\n",
    "ev.visualEvaluation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc79d07-4d85-4dba-8242-331e8102d0ca",
   "metadata": {},
   "source": [
    "## Registro del modelo en MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4654dd7-3e73-41b8-b7f8-eeb559fff34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/mlflow/pyfunc/utils/data_validation.py:186: UserWarning:\n",
      "\n",
      "\u001b[33mAdd type hints to the `predict` method to enable data validation and automatic signature inference during model logging. Check https://mlflow.org/docs/latest/model/python_model.html#type-hint-usage-in-pythonmodel for more details.\u001b[0m\n",
      "\n",
      "\u001b[31m2025/04/26 19:31:26 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"file:./mlflow_experiments\")\n",
    "mlflow.set_experiment(\"takeoff_time_prediction\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "\n",
    "    # - Datos generales -\n",
    "\n",
    "    # ========================================================================\n",
    "    mlflow.set_tag(\"model_type\", MODEL_NAME)\n",
    "    mlflow.set_tag(\"framework\", \"pandas\") # scikit-learn, tensorflow, etc.\n",
    "    mlflow.set_tag(\"target_variable\", \"takeoff_time\") # variable respuesta\n",
    "    mlflow.set_tag(\"preprocessing\", \"none\") # transformaciones separadas por un +\n",
    "    mlflow.set_tag(\"dataset\", \"original\") # indicar si se ha modificado el conjunto de datos\n",
    "    mlflow.set_tag(\"seed\", SEED) # semilla para replicabilidad\n",
    "    # ========================================================================\n",
    "    \n",
    "    \n",
    "    # - Métricas -\n",
    "\n",
    "    mlflow.log_metric(\"execution_time_s\", execution_time)\n",
    "\n",
    "    mlflow.log_metric(\"mae_train\", mae_train)\n",
    "    mlflow.log_metric(\"rmse_train\", rmse_train)\n",
    "\n",
    "    # Registrar métricas globales en test\n",
    "    for metric_name, value in report[\"global\"].items():\n",
    "        mlflow.log_metric(f\"{metric_name}_test\", value)\n",
    "    \n",
    "    # Registrar métricas por runway\n",
    "    for runway, metrics in report[\"by_runway\"].items():\n",
    "        for metric_name, value in metrics.items():\n",
    "            mlflow.log_metric(f\"{metric_name}_test_runway_{runway}\", value)\n",
    "    \n",
    "    # Registrar métricas por holding point\n",
    "    for hp, metrics in report[\"by_holding_point\"].items():\n",
    "        for metric_name, value in metrics.items():\n",
    "            mlflow.log_metric(f\"{metric_name}_test_hp_{hp}\", value)\n",
    "\n",
    "    # - Modelo -\n",
    "\n",
    "    import mlflow.pyfunc\n",
    "\n",
    "    class HeuristicModel(mlflow.pyfunc.PythonModel):\n",
    "        \n",
    "        def predict(self, context, model_input):\n",
    "            # model_input será un DataFrame\n",
    "            return model_input.apply(h, axis=1)\n",
    "    \n",
    "    model = HeuristicModel()\n",
    "    mlflow.pyfunc.log_model(\n",
    "        artifact_path=MODEL_NAME,\n",
    "        python_model=model\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa475d6-3fd2-41c8-9916-5ce17302c8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Visualizar experimentos -\n",
    "# !mlflow ui --backend-store-uri ./mlflow_experiments"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
