{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a38e49ff-48e2-4d22-8232-add20dc4cd8c",
   "metadata": {},
   "source": [
    "# MODELADO\n",
    "\n",
    "## HEURÍSTICA\n",
    "\n",
    "\n",
    "<hr>\n",
    "\n",
    "<code> **Proyecto de Datos II** </code>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7c845b-dd88-42f7-aba6-1e2778fa821a",
   "metadata": {},
   "source": [
    "## Índice\n",
    "\n",
    "- [Importación de los datos](#importación-de-los-datos)\n",
    "- [Preprocesamiento](#preprocesamiento)\n",
    "- [Entrenamiento](#entrenamiento)\n",
    "- [Análisis del modelo](#análisis-del-modelo)\n",
    "- [Registro del modelo en MLflow](#registro-del-modelo-en-mlflow)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2f464da-fc1a-45ba-a080-6cfde2316aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "from evaluation.evaluator import Evaluator\n",
    "\n",
    "SEED = 22 # replicabilidad\n",
    "\n",
    "# =====================================\n",
    "MODEL_NAME = \"Heurística I\"\n",
    "# ====================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd637b55-3e74-410d-819b-6aa19ed9c30e",
   "metadata": {},
   "source": [
    "## Importación de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aeffee5d-bee7-47cb-ad3a-da90737097b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_parquet(\"../data/train.parquet\")\n",
    "df_test = pd.read_parquet(\"../data/test.parquet\")\n",
    "\n",
    "# ! NOTA -> están el ICAO, Callsign y Timestamp por si hay que depurar\n",
    "X_train, y_train = df_train.drop(columns=\"takeoff_time\", axis=1), df_train[\"takeoff_time\"]\n",
    "X_test, y_test = df_test.drop(columns=\"takeoff_time\", axis=1), df_test[\"takeoff_time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ea6d533-6fcb-4a43-93f9-0fccd38e6198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((123733, 60), (27791, 60))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a847e73-4ee8-4336-9efb-d74bcbc788c9",
   "metadata": {},
   "source": [
    "## Preprocesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cc8f9e-7c86-4ec4-9499-457e30ebd49a",
   "metadata": {},
   "source": [
    "Para la heurística definida no será necesario ningún tipo de preprocesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25078f0-34aa-4eca-acac-646f3b819823",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf23aa9-a8b0-4f9f-9052-6e4ee1dc5413",
   "metadata": {},
   "source": [
    "Definimos la heurística:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71862d1c-3518-4459-8614-7d57b55f498c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def h(row):\n",
    "    \n",
    "    # Base time (en segundos)\n",
    "    base_time = 100\n",
    "    \n",
    "    # - Ajustes por tráfico reciente -\n",
    "    traffic = row['last_min_takeoffs'] + row['last_min_landings']\n",
    "    if traffic > 5:\n",
    "        base_time += 40\n",
    "    elif traffic > 3:\n",
    "        base_time += 20\n",
    "    else:\n",
    "        base_time += 5\n",
    "    \n",
    "    # - Ajustes por categoría de turbulencia -\n",
    "    if row['last_event_turb_cat'].startswith('H'):  # Heavy\n",
    "        base_time += 30\n",
    "    elif row['last_event_turb_cat'].startswith('M'):  # Medium\n",
    "        base_time += 15\n",
    "    \n",
    "    # - Ajuste por tiempo desde el último evento -\n",
    "    if row['time_since_last_event_seconds'] < 60:\n",
    "        base_time += (60 - row['time_since_last_event_seconds']) # más cercano, más espera\n",
    "    \n",
    "    # - Ajuste por hora pico -\n",
    "    if 7 <= row['hour'] <= 10 or 17 <= row['hour'] <= 20:  # Mañana y tarde\n",
    "        base_time += 100\n",
    "        \n",
    "    # - Ajuste si es festivo -\n",
    "    if row['is_holiday']:\n",
    "        base_time -= 30  # menos tráfico\n",
    "    \n",
    "    return max(base_time, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98e6f69a-b80b-45e9-8629-790298d53b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "df_train['prediction'] = df_train.apply(h, axis=1)\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7970bbdb-c953-4e17-8bb8-c99b1187dd03",
   "metadata": {},
   "source": [
    "## Análisis del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6cd1f60-b05f-4ef2-b806-15ac8b31e0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# ===============================================================\n",
    "y_true = df_train['takeoff_time']\n",
    "y_pred = df_train['prediction']\n",
    "\n",
    "mae_train = mean_absolute_error(y_true, y_pred)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "mae_val = None\n",
    "rmse_val = None\n",
    "# ==============================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1469d262-f7d3-4167-9291-07bb4b685fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "# Generar predicciones en test\n",
    "df_test['prediction'] = df_test.apply(h, axis=1)\n",
    "# ==============================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18706da7-ae3b-4003-8bcb-6dc73a0194ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1642cda30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Nota: df_test tiene que tener la columna 'prediction'\n",
    "ev = Evaluator(df_test, MODEL_NAME)\n",
    "report = ev.getReport()\n",
    "ev.visualEvaluation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc79d07-4d85-4dba-8242-331e8102d0ca",
   "metadata": {},
   "source": [
    "## Registro del modelo en MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4654dd7-3e73-41b8-b7f8-eeb559fff34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/mlflow/pyfunc/utils/data_validation.py:186: UserWarning:\n",
      "\n",
      "\u001b[33mAdd type hints to the `predict` method to enable data validation and automatic signature inference during model logging. Check https://mlflow.org/docs/latest/model/python_model.html#type-hint-usage-in-pythonmodel for more details.\u001b[0m\n",
      "\n",
      "\u001b[31m2025/04/29 18:24:14 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"file:./mlflow_experiments\")\n",
    "mlflow.set_experiment(\"takeoff_time_prediction\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "\n",
    "    # - Datos generales -\n",
    "\n",
    "    # ========================================================================\n",
    "    mlflow.set_tag(\"model_type\", MODEL_NAME)\n",
    "    mlflow.set_tag(\"framework\", \"pandas\") # scikit-learn, tensorflow, etc.\n",
    "    mlflow.set_tag(\"target_variable\", \"takeoff_time\") # variable respuesta\n",
    "    mlflow.set_tag(\"preprocessing\", \"none\") # transformaciones separadas por un +\n",
    "    mlflow.set_tag(\"dataset\", \"original\") # indicar si se ha modificado el conjunto de datos\n",
    "    mlflow.set_tag(\"seed\", SEED) # semilla para replicabilidad\n",
    "    # ========================================================================\n",
    "    \n",
    "    \n",
    "    # - Métricas -\n",
    "\n",
    "    mlflow.log_metric(\"execution_time_s\", execution_time)\n",
    "\n",
    "    mlflow.log_metric(\"mae_train\", mae_train)\n",
    "    mlflow.log_metric(\"rmse_train\", rmse_train)\n",
    "\n",
    "    # Registrar métricas globales en test\n",
    "    for metric_name, value in report[\"global\"].items():\n",
    "        mlflow.log_metric(f\"{metric_name}_test\", value)\n",
    "    \n",
    "    # Registrar métricas por runway\n",
    "    for runway, metrics in report[\"by_runway\"].items():\n",
    "        for metric_name, value in metrics.items():\n",
    "            mlflow.log_metric(f\"{metric_name}_test_runway_{runway}\", value)\n",
    "    \n",
    "    # Registrar métricas por holding point\n",
    "    for hp, metrics in report[\"by_holding_point\"].items():\n",
    "        for metric_name, value in metrics.items():\n",
    "            mlflow.log_metric(f\"{metric_name}_test_hp_{hp}\", value)\n",
    "\n",
    "    # - Modelo -\n",
    "\n",
    "    import mlflow.pyfunc\n",
    "\n",
    "    class HeuristicModel(mlflow.pyfunc.PythonModel):\n",
    "        \n",
    "        def predict(self, context, model_input):\n",
    "            # model_input será un DataFrame\n",
    "            return model_input.apply(h, axis=1)\n",
    "    \n",
    "    model = HeuristicModel()\n",
    "    mlflow.pyfunc.log_model(\n",
    "        artifact_path=MODEL_NAME,\n",
    "        python_model=model\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a375825-ec46-4859-bb51-06b73c56ff50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-26 14:52:59 +0200] [77373] [INFO] Starting gunicorn 23.0.0\n",
      "[2025-04-26 14:52:59 +0200] [77373] [INFO] Listening at: http://127.0.0.1:5000 (77373)\n",
      "[2025-04-26 14:52:59 +0200] [77373] [INFO] Using worker: sync\n",
      "[2025-04-26 14:52:59 +0200] [77374] [INFO] Booting worker with pid: 77374\n",
      "[2025-04-26 14:53:00 +0200] [77375] [INFO] Booting worker with pid: 77375\n",
      "[2025-04-26 14:53:00 +0200] [77376] [INFO] Booting worker with pid: 77376\n",
      "[2025-04-26 14:53:00 +0200] [77384] [INFO] Booting worker with pid: 77384\n"
     ]
    }
   ],
   "source": [
    "!mlflow ui --backend-store-uri ./mlflow_experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5b89e7-32af-4f10-92e1-0555e53cf1c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
